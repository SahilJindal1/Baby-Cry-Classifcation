{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dual Features (fixed length).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMumwTQZN27Bn0HfOSQLESf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pvTDt3Eut4tp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQMc4fiU3nLh","executionInfo":{"status":"ok","timestamp":1602237147674,"user_tz":-330,"elapsed":1696,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"62d9b924-1900-4353-a2fa-27b719856ee2","colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FY1QY9VfgesA"},"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n","from tensorflow.keras.applications import VGG16, MobileNetV2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HkzgBFSBmmla","executionInfo":{"status":"ok","timestamp":1600091253068,"user_tz":-330,"elapsed":1678,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"916758a8-547c-4df6-d286-30e378ea6fd2","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["# To be used by vinayak Sir. Kindly take the different dataset of image files. There were some changes. Some files were removed. Contact for reasons \n","\"\"\"\n","import numpy as np\n","import cv2\n","import os\n","from tensorflow.keras.utils import to_categorical\n","\n","instances_train = []\n","labels_train = []\n","\n","# Load in the images\n","for filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/train\"):\n","    print(filepath)\n","    for filename in os.listdir('drive/My Drive/03-06-2020 Image Files/train/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_train.append(cv2.imread('/content/drive/My Drive/03-06-2020 Image Files/train/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_train.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_train.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_train.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_train.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_train.append(4)\n","\n","instances_test = []\n","labels_test = []\n","\n","for filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/test\"):\n","    print(filepath)\n","    for filename in os.listdir('drive/My Drive/03-06-2020 Image Files/test/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_test.append(cv2.imread('drive/My Drive/03-06-2020 Image Files/test/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_test.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_test.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_test.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_test.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_test.append(4)\n","\n","\n","instances_val = []\n","labels_val = []\n","\n","for filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/val\"):\n","    print(filepath)\n","    for filename in os.listdir('drive/My Drive/03-06-2020 Image Files/val/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_val.append(cv2.imread('drive/My Drive/03-06-2020 Image Files/val/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_val.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_val.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_val.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_val.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_val.append(4)\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nimport numpy as np\\nimport cv2\\nimport os\\nfrom tensorflow.keras.utils import to_categorical\\n\\ninstances_train = []\\nlabels_train = []\\n\\n# Load in the images\\nfor filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/train\"):\\n    print(filepath)\\n    for filename in os.listdir(\\'drive/My Drive/03-06-2020 Image Files/train/{0}\\'.format(filepath)):\\n      if filename.endswith(\".png\"):\\n        #print(filename)\\n        instances_train.append(cv2.imread(\\'/content/drive/My Drive/03-06-2020 Image Files/train/{}/{}\\'.format(filepath,filename),1))\\n        #print(\\'/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}\\'.format(one = filepath,two = filename))\\n        if (filepath == \"belly_pain\"):\\n          labels_train.append(0)\\n        elif (filepath == \"burping\" ):\\n          labels_train.append(1)\\n        elif (filepath == \"discomfort\" ):\\n          labels_train.append(2)\\n        elif (filepath == \"hungry\" ):\\n          labels_train.append(3)\\n        elif (filepath == \"tired\" ):\\n          labels_train.append(4)\\n\\ninstances_test = []\\nlabels_test = []\\n\\nfor filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/test\"):\\n    print(filepath)\\n    for filename in os.listdir(\\'drive/My Drive/03-06-2020 Image Files/test/{0}\\'.format(filepath)):\\n      if filename.endswith(\".png\"):\\n        #print(filename)\\n        instances_test.append(cv2.imread(\\'drive/My Drive/03-06-2020 Image Files/test/{}/{}\\'.format(filepath,filename),1))\\n        #print(\\'/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}\\'.format(one = filepath,two = filename))\\n        if (filepath == \"belly_pain\"):\\n          labels_test.append(0)\\n        elif (filepath == \"burping\" ):\\n          labels_test.append(1)\\n        elif (filepath == \"discomfort\" ):\\n          labels_test.append(2)\\n        elif (filepath == \"hungry\" ):\\n          labels_test.append(3)\\n        elif (filepath == \"tired\" ):\\n          labels_test.append(4)\\n\\n\\ninstances_val = []\\nlabels_val = []\\n\\nfor filepath in os.listdir(r\"drive/My Drive/03-06-2020 Image Files/val\"):\\n    print(filepath)\\n    for filename in os.listdir(\\'drive/My Drive/03-06-2020 Image Files/val/{0}\\'.format(filepath)):\\n      if filename.endswith(\".png\"):\\n        #print(filename)\\n        instances_val.append(cv2.imread(\\'drive/My Drive/03-06-2020 Image Files/val/{}/{}\\'.format(filepath,filename),1))\\n        #print(\\'/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}\\'.format(one = filepath,two = filename))\\n        if (filepath == \"belly_pain\"):\\n          labels_val.append(0)\\n        elif (filepath == \"burping\" ):\\n          labels_val.append(1)\\n        elif (filepath == \"discomfort\" ):\\n          labels_val.append(2)\\n        elif (filepath == \"hungry\" ):\\n          labels_val.append(3)\\n        elif (filepath == \"tired\" ):\\n          labels_val.append(4)\\n'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"M1tWMGK_0ztx","executionInfo":{"status":"ok","timestamp":1602237156794,"user_tz":-330,"elapsed":6975,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"da1a82a1-0355-4dfb-fd4b-72bd53683c83","colab":{"base_uri":"https://localhost:8080/","height":268}},"source":["import numpy as np\n","import cv2\n","import os\n","\n","instances_train = []\n","labels_train = []\n","\n","# Load in the images\n","for filepath in os.listdir(r\"/content/drive/My Drive/Baby Cry/Make_Spectrogram/train\"):\n","    print(filepath)\n","    for filename in os.listdir('/content/drive/My Drive/Baby Cry/Make_Spectrogram/train/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_train.append(cv2.imread('/content/drive/My Drive/Baby Cry/Make_Spectrogram/train/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_train.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_train.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_train.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_train.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_train.append(4)\n","\n","instances_test = []\n","labels_test = []\n","\n","for filepath in os.listdir(r\"/content/drive/My Drive/Baby Cry/Make_Spectrogram/test\"):\n","    print(filepath)\n","    for filename in os.listdir('/content/drive/My Drive/Baby Cry/Make_Spectrogram/test/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_test.append(cv2.imread('/content/drive/My Drive/Baby Cry/Make_Spectrogram/test/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_test.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_test.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_test.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_test.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_test.append(4)\n","\n","\n","instances_val = []\n","labels_val = []\n","\n","for filepath in os.listdir(r\"/content/drive/My Drive/Baby Cry/Make_Spectrogram/val\"):\n","    print(filepath)\n","    for filename in os.listdir('/content/drive/My Drive/Baby Cry/Make_Spectrogram/val/{0}'.format(filepath)):\n","      if filename.endswith(\".png\"):\n","        #print(filename)\n","        instances_val.append(cv2.imread('/content/drive/My Drive/Baby Cry/Make_Spectrogram/val/{}/{}'.format(filepath,filename),1))\n","        #print('/content/drive/My Drive/Baby Cry/donateacry-corpus-master/03-06-2020 Image Files/train/{one}/{two}'.format(one = filepath,two = filename))\n","        if (filepath == \"belly_pain\"):\n","          labels_val.append(0)\n","        elif (filepath == \"burping\" ):\n","          labels_val.append(1)\n","        elif (filepath == \"discomfort\" ):\n","          labels_val.append(2)\n","        elif (filepath == \"hungry\" ):\n","          labels_val.append(3)\n","        elif (filepath == \"tired\" ):\n","          labels_val.append(4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["belly_pain\n","burping\n","hungry\n","tired\n","discomfort\n","belly_pain\n","burping\n","hungry\n","tired\n","discomfort\n","belly_pain\n","burping\n","hungry\n","tired\n","discomfort\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eHQW35BOpA2-"},"source":["X_train_orig = np.array(instances_train)\n","X_test_orig = np.array(instances_test)\n","X_val_orig = np.array(instances_val)\n","\n","Y_train_orig = np.array(labels_train)\n","Y_test_orig = np.array(labels_test)\n","Y_val_orig = np.array(labels_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KIqdd8HSncQJ"},"source":["#optional for trial on both train and validation data together\n","X_train_orig = np.concatenate((X_train_orig,X_val_orig))\n","Y_train_orig = np.concatenate((Y_train_orig,Y_val_orig))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RSmEpAtm2e_"},"source":["# Normalize image vectors\n","X_train = X_train_orig/255.\n","X_val = X_val_orig/255.\n","X_test = X_test_orig/255.\n","\n","# Convert training and test labels to one hot matrices\n","Y_train = to_categorical(Y_train_orig)\n","Y_val = to_categorical(Y_val_orig)\n","Y_test = to_categorical(Y_test_orig)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3_oGbO4Ode5","executionInfo":{"status":"ok","timestamp":1602237157918,"user_tz":-330,"elapsed":2094,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"fed334a4-b127-436d-93e1-42b55d84c4d2","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(X_train.shape)\n","print(X_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 288, 432, 3)\n","(152, 288, 432, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VRJrLXdVgepc"},"source":["# load VGG16, ensuring the head FC layer sets are left off, while at the same time adjusting the size of the input image tensor to the network\n","baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(288,432, 3)))\n","#baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(288,432, 3)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcNoRVh_gemc"},"source":["# add layers for transfer learning\n","headModel = baseModel.output\n","headModel = AveragePooling2D(pool_size=(4, 4),name = 'averagepool_last')(headModel)\n","headModel = Flatten(name=\"flatten\")(headModel)\n","#headModel = Dense(1024, activation=\"relu\")(headModel)\n","headModel = Dense(512, activation=\"relu\",name = 'dense_512')(headModel)\n","headModel = Dense(128, activation=\"relu\",name = 'dense_128')(headModel)   # we can experiment with more dense layers if output of average pooling layer is too big\n","headModel = Dropout(0.3,name = 'dropout_last')(headModel)\n","headModel = Dense(5, activation=\"softmax\",name = 'output')(headModel)  # we have 5 classes\n","\n","# place the head FC model on top of the base model (this will become\n","# the actual model we will train)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","#model.summary()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"81gKjPlbNiaT"},"source":["#------------Optional: We can train only Classification layers with below code or do training from scratch with keras.fit()\n","# loop over all layers in the base model and freeze them so they will\n","# *not* be updated during the first training process\n","# for layer in baseModel.layers:\n","#   layer.trainable = False\n","\n","###for models with Batch-Norm  \n","for layer in baseModel.layers:\n","  if layer.__class__.__name__=='BatchNormalization':\n","    #print('exist')\n","    layer.trainable = False\n","  #else:\n","    #print('normal layer')  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhnkZhbBszHH"},"source":["# adding regularization\n","regularizer = tf.keras.regularizers.l2(.0001)\n","\n","for layer in model.layers:\n","  if layer.trainable == True:\n","    for attr in ['kernel_regularizer']:\n","        if hasattr(layer, attr):\n","          setattr(layer, attr, regularizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCaW7eE_gej_","executionInfo":{"status":"ok","timestamp":1602237169526,"user_tz":-330,"elapsed":1393,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"a6e21043-6779-49bc-8856-1fc7366bd0b8","colab":{"base_uri":"https://localhost:8080/","height":987}},"source":["#opt=SGD(learning_rate=1e-4, nesterov=True)\n","#opt=tf.keras.optimizers.Nadam(learning_rate=1e-4)\n","\n","opt=Adam(lr=1e-4)\n","model.compile(loss='categorical_crossentropy', optimizer=opt,\tmetrics=[\"accuracy\"])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 288, 432, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 288, 432, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 288, 432, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 144, 216, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 144, 216, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 144, 216, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 72, 108, 128)      0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 72, 108, 256)      295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 36, 54, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 36, 54, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 36, 54, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 36, 54, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 18, 27, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 9, 13, 512)        0         \n","_________________________________________________________________\n","averagepool_last (AveragePoo (None, 2, 3, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3072)              0         \n","_________________________________________________________________\n","dense_512 (Dense)            (None, 512)               1573376   \n","_________________________________________________________________\n","dense_128 (Dense)            (None, 128)               65664     \n","_________________________________________________________________\n","dropout_last (Dropout)       (None, 128)               0         \n","_________________________________________________________________\n","output (Dense)               (None, 5)                 645       \n","=================================================================\n","Total params: 16,354,373\n","Trainable params: 16,354,373\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BHdjfzS8Mi_j"},"source":["import tensorflow as tf\n","#callback for best Val Accuracy\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=\"/content/best.ckpt\",\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVPcB6MLgehi","executionInfo":{"status":"ok","timestamp":1600083385019,"user_tz":-330,"elapsed":1166281,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"f3dca29b-1616-4825-9513-e3e4206f9101","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Mobilenet trial\n","model.fit(X_train, Y_train, batch_size=32,\tvalidation_data=(X_test, Y_test),\tepochs=100, verbose=2, callbacks=[model_checkpoint_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1302s vs `on_train_batch_end` time: 0.4400s). Check your callbacks.\n","19/19 - 13s - loss: 1.4154 - accuracy: 0.4909 - val_loss: 1.3495 - val_accuracy: 0.5066\n","Epoch 2/100\n","19/19 - 11s - loss: 1.2918 - accuracy: 0.5223 - val_loss: 1.2135 - val_accuracy: 0.5658\n","Epoch 3/100\n","19/19 - 12s - loss: 1.2416 - accuracy: 0.5504 - val_loss: 1.0832 - val_accuracy: 0.5987\n","Epoch 4/100\n","19/19 - 11s - loss: 1.1534 - accuracy: 0.6083 - val_loss: 1.1403 - val_accuracy: 0.5921\n","Epoch 5/100\n","19/19 - 11s - loss: 1.1234 - accuracy: 0.6050 - val_loss: 1.0354 - val_accuracy: 0.5855\n","Epoch 6/100\n","19/19 - 12s - loss: 1.1006 - accuracy: 0.5901 - val_loss: 1.2290 - val_accuracy: 0.5592\n","Epoch 7/100\n","19/19 - 11s - loss: 1.0927 - accuracy: 0.5983 - val_loss: 1.0460 - val_accuracy: 0.5987\n","Epoch 8/100\n","19/19 - 12s - loss: 1.0579 - accuracy: 0.5934 - val_loss: 1.1369 - val_accuracy: 0.5789\n","Epoch 9/100\n","19/19 - 11s - loss: 1.1184 - accuracy: 0.5967 - val_loss: 1.0259 - val_accuracy: 0.5987\n","Epoch 10/100\n","19/19 - 11s - loss: 1.0322 - accuracy: 0.6149 - val_loss: 1.1224 - val_accuracy: 0.5724\n","Epoch 11/100\n","19/19 - 11s - loss: 1.0401 - accuracy: 0.6231 - val_loss: 1.1035 - val_accuracy: 0.5592\n","Epoch 12/100\n","19/19 - 12s - loss: 0.9112 - accuracy: 0.6364 - val_loss: 1.0086 - val_accuracy: 0.6184\n","Epoch 13/100\n","19/19 - 11s - loss: 0.8646 - accuracy: 0.6612 - val_loss: 1.2632 - val_accuracy: 0.5526\n","Epoch 14/100\n","19/19 - 11s - loss: 0.8583 - accuracy: 0.6744 - val_loss: 1.0692 - val_accuracy: 0.5789\n","Epoch 15/100\n","19/19 - 11s - loss: 0.7888 - accuracy: 0.6942 - val_loss: 0.9942 - val_accuracy: 0.6184\n","Epoch 16/100\n","19/19 - 11s - loss: 0.7859 - accuracy: 0.7091 - val_loss: 1.1212 - val_accuracy: 0.5263\n","Epoch 17/100\n","19/19 - 12s - loss: 0.7013 - accuracy: 0.7322 - val_loss: 1.1140 - val_accuracy: 0.5724\n","Epoch 18/100\n","19/19 - 11s - loss: 0.6268 - accuracy: 0.7554 - val_loss: 1.1584 - val_accuracy: 0.5789\n","Epoch 19/100\n","19/19 - 11s - loss: 0.6027 - accuracy: 0.7818 - val_loss: 1.1737 - val_accuracy: 0.6118\n","Epoch 20/100\n","19/19 - 11s - loss: 0.4758 - accuracy: 0.8231 - val_loss: 1.1400 - val_accuracy: 0.5987\n","Epoch 21/100\n","19/19 - 11s - loss: 0.4371 - accuracy: 0.8215 - val_loss: 1.5006 - val_accuracy: 0.5987\n","Epoch 22/100\n","19/19 - 11s - loss: 0.2835 - accuracy: 0.9041 - val_loss: 1.4902 - val_accuracy: 0.5789\n","Epoch 23/100\n","19/19 - 12s - loss: 0.2929 - accuracy: 0.9091 - val_loss: 1.5147 - val_accuracy: 0.6053\n","Epoch 24/100\n","19/19 - 11s - loss: 0.2362 - accuracy: 0.9107 - val_loss: 1.7864 - val_accuracy: 0.6118\n","Epoch 25/100\n","19/19 - 12s - loss: 0.3283 - accuracy: 0.8810 - val_loss: 1.3151 - val_accuracy: 0.6184\n","Epoch 26/100\n","19/19 - 11s - loss: 0.1802 - accuracy: 0.9339 - val_loss: 1.5538 - val_accuracy: 0.6053\n","Epoch 27/100\n","19/19 - 11s - loss: 0.1372 - accuracy: 0.9537 - val_loss: 1.8152 - val_accuracy: 0.5987\n","Epoch 28/100\n","19/19 - 12s - loss: 0.0877 - accuracy: 0.9702 - val_loss: 2.0843 - val_accuracy: 0.6513\n","Epoch 29/100\n","19/19 - 11s - loss: 0.1344 - accuracy: 0.9570 - val_loss: 1.7624 - val_accuracy: 0.6053\n","Epoch 30/100\n","19/19 - 12s - loss: 0.3030 - accuracy: 0.8826 - val_loss: 1.5123 - val_accuracy: 0.6118\n","Epoch 31/100\n","19/19 - 11s - loss: 0.1234 - accuracy: 0.9603 - val_loss: 2.0178 - val_accuracy: 0.6184\n","Epoch 32/100\n","19/19 - 11s - loss: 0.4928 - accuracy: 0.8281 - val_loss: 1.2685 - val_accuracy: 0.6382\n","Epoch 33/100\n","19/19 - 11s - loss: 0.1957 - accuracy: 0.9587 - val_loss: 1.7486 - val_accuracy: 0.5987\n","Epoch 34/100\n","19/19 - 11s - loss: 0.0615 - accuracy: 0.9835 - val_loss: 1.8167 - val_accuracy: 0.5724\n","Epoch 35/100\n","19/19 - 11s - loss: 0.0964 - accuracy: 0.9653 - val_loss: 1.9237 - val_accuracy: 0.5724\n","Epoch 36/100\n","19/19 - 11s - loss: 0.0684 - accuracy: 0.9802 - val_loss: 1.9048 - val_accuracy: 0.6250\n","Epoch 37/100\n","19/19 - 11s - loss: 0.0197 - accuracy: 0.9950 - val_loss: 2.0424 - val_accuracy: 0.6382\n","Epoch 38/100\n","19/19 - 12s - loss: 0.0164 - accuracy: 0.9967 - val_loss: 2.1349 - val_accuracy: 0.6382\n","Epoch 39/100\n","19/19 - 12s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.3293 - val_accuracy: 0.6776\n","Epoch 40/100\n","19/19 - 12s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.3502 - val_accuracy: 0.6645\n","Epoch 41/100\n","19/19 - 12s - loss: 3.5923e-04 - accuracy: 1.0000 - val_loss: 2.3122 - val_accuracy: 0.6711\n","Epoch 42/100\n","19/19 - 11s - loss: 8.5116e-04 - accuracy: 1.0000 - val_loss: 2.2939 - val_accuracy: 0.6579\n","Epoch 43/100\n","19/19 - 12s - loss: 9.2730e-04 - accuracy: 1.0000 - val_loss: 2.3407 - val_accuracy: 0.6908\n","Epoch 44/100\n","19/19 - 11s - loss: 2.9376e-04 - accuracy: 1.0000 - val_loss: 2.3936 - val_accuracy: 0.6842\n","Epoch 45/100\n","19/19 - 12s - loss: 2.9587e-04 - accuracy: 1.0000 - val_loss: 2.3797 - val_accuracy: 0.6842\n","Epoch 46/100\n","19/19 - 12s - loss: 5.6973e-04 - accuracy: 1.0000 - val_loss: 2.3809 - val_accuracy: 0.6645\n","Epoch 47/100\n","19/19 - 11s - loss: 1.9552e-04 - accuracy: 1.0000 - val_loss: 2.4342 - val_accuracy: 0.6776\n","Epoch 48/100\n","19/19 - 11s - loss: 2.1301e-04 - accuracy: 1.0000 - val_loss: 2.4539 - val_accuracy: 0.6711\n","Epoch 49/100\n","19/19 - 11s - loss: 4.1508e-04 - accuracy: 1.0000 - val_loss: 2.4550 - val_accuracy: 0.6645\n","Epoch 50/100\n","19/19 - 11s - loss: 1.7565e-04 - accuracy: 1.0000 - val_loss: 2.4731 - val_accuracy: 0.6645\n","Epoch 51/100\n","19/19 - 11s - loss: 2.4367e-04 - accuracy: 1.0000 - val_loss: 2.4872 - val_accuracy: 0.6645\n","Epoch 52/100\n","19/19 - 11s - loss: 1.9447e-04 - accuracy: 1.0000 - val_loss: 2.5068 - val_accuracy: 0.6711\n","Epoch 53/100\n","19/19 - 11s - loss: 1.7291e-04 - accuracy: 1.0000 - val_loss: 2.5192 - val_accuracy: 0.6711\n","Epoch 54/100\n","19/19 - 12s - loss: 1.8089e-04 - accuracy: 1.0000 - val_loss: 2.5182 - val_accuracy: 0.6645\n","Epoch 55/100\n","19/19 - 11s - loss: 1.3023e-04 - accuracy: 1.0000 - val_loss: 2.5391 - val_accuracy: 0.6579\n","Epoch 56/100\n","19/19 - 11s - loss: 1.0153e-04 - accuracy: 1.0000 - val_loss: 2.5666 - val_accuracy: 0.6711\n","Epoch 57/100\n","19/19 - 11s - loss: 1.4195e-04 - accuracy: 1.0000 - val_loss: 2.5719 - val_accuracy: 0.6645\n","Epoch 58/100\n","19/19 - 12s - loss: 1.6968e-04 - accuracy: 1.0000 - val_loss: 2.5986 - val_accuracy: 0.6645\n","Epoch 59/100\n","19/19 - 11s - loss: 7.8439e-05 - accuracy: 1.0000 - val_loss: 2.6069 - val_accuracy: 0.6645\n","Epoch 60/100\n","19/19 - 11s - loss: 4.4834e-04 - accuracy: 1.0000 - val_loss: 2.6435 - val_accuracy: 0.6776\n","Epoch 61/100\n","19/19 - 11s - loss: 1.9439e-04 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.6513\n","Epoch 62/100\n","19/19 - 12s - loss: 1.4951e-04 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.6513\n","Epoch 63/100\n","19/19 - 11s - loss: 1.2143e-04 - accuracy: 1.0000 - val_loss: 2.7243 - val_accuracy: 0.6579\n","Epoch 64/100\n","19/19 - 11s - loss: 1.5710e-04 - accuracy: 1.0000 - val_loss: 2.6795 - val_accuracy: 0.6645\n","Epoch 65/100\n","19/19 - 11s - loss: 7.9611e-05 - accuracy: 1.0000 - val_loss: 2.6862 - val_accuracy: 0.6776\n","Epoch 66/100\n","19/19 - 11s - loss: 8.9677e-05 - accuracy: 1.0000 - val_loss: 2.7217 - val_accuracy: 0.6776\n","Epoch 67/100\n","19/19 - 11s - loss: 1.7201e-04 - accuracy: 1.0000 - val_loss: 2.7358 - val_accuracy: 0.6776\n","Epoch 68/100\n","19/19 - 11s - loss: 1.8135e-04 - accuracy: 1.0000 - val_loss: 2.7502 - val_accuracy: 0.6842\n","Epoch 69/100\n","19/19 - 11s - loss: 7.5950e-05 - accuracy: 1.0000 - val_loss: 2.7666 - val_accuracy: 0.6842\n","Epoch 70/100\n","19/19 - 12s - loss: 9.0170e-05 - accuracy: 1.0000 - val_loss: 2.7707 - val_accuracy: 0.6842\n","Epoch 71/100\n","19/19 - 11s - loss: 1.1345e-04 - accuracy: 1.0000 - val_loss: 2.7774 - val_accuracy: 0.6711\n","Epoch 72/100\n","19/19 - 12s - loss: 1.2688e-04 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.6842\n","Epoch 73/100\n","19/19 - 11s - loss: 7.3981e-05 - accuracy: 1.0000 - val_loss: 2.8252 - val_accuracy: 0.6908\n","Epoch 74/100\n","19/19 - 11s - loss: 1.0049e-04 - accuracy: 1.0000 - val_loss: 2.8247 - val_accuracy: 0.6842\n","Epoch 75/100\n","19/19 - 11s - loss: 1.2507e-04 - accuracy: 1.0000 - val_loss: 2.8947 - val_accuracy: 0.6711\n","Epoch 76/100\n","19/19 - 11s - loss: 1.3529e-04 - accuracy: 1.0000 - val_loss: 2.8448 - val_accuracy: 0.6842\n","Epoch 77/100\n","19/19 - 12s - loss: 1.0330e-04 - accuracy: 1.0000 - val_loss: 2.8074 - val_accuracy: 0.6776\n","Epoch 78/100\n","19/19 - 12s - loss: 3.7618e-05 - accuracy: 1.0000 - val_loss: 2.8018 - val_accuracy: 0.6711\n","Epoch 79/100\n","19/19 - 11s - loss: 3.1570e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.6711\n","Epoch 80/100\n","19/19 - 11s - loss: 3.4120e-05 - accuracy: 1.0000 - val_loss: 2.8204 - val_accuracy: 0.6711\n","Epoch 81/100\n","19/19 - 11s - loss: 2.3944e-05 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.6711\n","Epoch 82/100\n","19/19 - 12s - loss: 3.2052e-05 - accuracy: 1.0000 - val_loss: 2.8323 - val_accuracy: 0.6711\n","Epoch 83/100\n","19/19 - 11s - loss: 6.9227e-05 - accuracy: 1.0000 - val_loss: 2.8307 - val_accuracy: 0.6711\n","Epoch 84/100\n","19/19 - 11s - loss: 1.0222e-04 - accuracy: 1.0000 - val_loss: 2.8302 - val_accuracy: 0.6711\n","Epoch 85/100\n","19/19 - 11s - loss: 4.6455e-05 - accuracy: 1.0000 - val_loss: 2.8469 - val_accuracy: 0.6908\n","Epoch 86/100\n","19/19 - 12s - loss: 3.3274e-05 - accuracy: 1.0000 - val_loss: 2.8616 - val_accuracy: 0.6908\n","Epoch 87/100\n","19/19 - 11s - loss: 4.0566e-05 - accuracy: 1.0000 - val_loss: 2.8787 - val_accuracy: 0.6842\n","Epoch 88/100\n","19/19 - 11s - loss: 3.4331e-05 - accuracy: 1.0000 - val_loss: 2.8829 - val_accuracy: 0.6776\n","Epoch 89/100\n","19/19 - 11s - loss: 2.8973e-05 - accuracy: 1.0000 - val_loss: 2.8894 - val_accuracy: 0.6776\n","Epoch 90/100\n","19/19 - 11s - loss: 8.1312e-05 - accuracy: 1.0000 - val_loss: 2.8870 - val_accuracy: 0.6776\n","Epoch 91/100\n","19/19 - 11s - loss: 5.2197e-05 - accuracy: 1.0000 - val_loss: 2.9118 - val_accuracy: 0.6842\n","Epoch 92/100\n","19/19 - 11s - loss: 3.3776e-05 - accuracy: 1.0000 - val_loss: 2.9373 - val_accuracy: 0.6842\n","Epoch 93/100\n","19/19 - 12s - loss: 4.6712e-05 - accuracy: 1.0000 - val_loss: 2.9405 - val_accuracy: 0.6842\n","Epoch 94/100\n","19/19 - 12s - loss: 5.5810e-05 - accuracy: 1.0000 - val_loss: 2.9327 - val_accuracy: 0.6776\n","Epoch 95/100\n","19/19 - 12s - loss: 2.6019e-05 - accuracy: 1.0000 - val_loss: 2.9319 - val_accuracy: 0.6776\n","Epoch 96/100\n","19/19 - 11s - loss: 3.1041e-05 - accuracy: 1.0000 - val_loss: 2.9378 - val_accuracy: 0.6776\n","Epoch 97/100\n","19/19 - 11s - loss: 5.2993e-05 - accuracy: 1.0000 - val_loss: 2.9491 - val_accuracy: 0.6842\n","Epoch 98/100\n","19/19 - 12s - loss: 2.1033e-05 - accuracy: 1.0000 - val_loss: 2.9636 - val_accuracy: 0.6842\n","Epoch 99/100\n","19/19 - 11s - loss: 3.1314e-05 - accuracy: 1.0000 - val_loss: 2.9698 - val_accuracy: 0.6842\n","Epoch 100/100\n","19/19 - 12s - loss: 4.7161e-05 - accuracy: 1.0000 - val_loss: 2.9860 - val_accuracy: 0.6908\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fec18039518>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"vBbPhz59KvHx","executionInfo":{"status":"ok","timestamp":1602241711166,"user_tz":-330,"elapsed":4450277,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"5d28fb7c-2d4a-4a13-8f3d-bbf713f61540","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#VGG16 trial\n","model.fit(X_train, Y_train, batch_size=32,\tvalidation_data=(X_test, Y_test),\tepochs=100, verbose=2, callbacks=[model_checkpoint_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6268s vs `on_train_batch_end` time: 1.5469s). Check your callbacks.\n","19/19 - 61s - loss: 1.3384 - accuracy: 0.5124 - val_loss: 1.3720 - val_accuracy: 0.4145\n","Epoch 2/100\n","19/19 - 44s - loss: 1.2121 - accuracy: 0.5686 - val_loss: 1.0958 - val_accuracy: 0.5921\n","Epoch 3/100\n","19/19 - 44s - loss: 1.1297 - accuracy: 0.5818 - val_loss: 1.0539 - val_accuracy: 0.5987\n","Epoch 4/100\n","19/19 - 44s - loss: 1.1284 - accuracy: 0.5950 - val_loss: 1.1070 - val_accuracy: 0.6250\n","Epoch 5/100\n","19/19 - 44s - loss: 1.0627 - accuracy: 0.5967 - val_loss: 1.0441 - val_accuracy: 0.5855\n","Epoch 6/100\n","19/19 - 43s - loss: 0.9960 - accuracy: 0.6529 - val_loss: 1.0767 - val_accuracy: 0.6053\n","Epoch 7/100\n","19/19 - 44s - loss: 0.9437 - accuracy: 0.6347 - val_loss: 0.9775 - val_accuracy: 0.6316\n","Epoch 8/100\n","19/19 - 44s - loss: 0.8151 - accuracy: 0.6628 - val_loss: 1.0308 - val_accuracy: 0.6250\n","Epoch 9/100\n","19/19 - 44s - loss: 0.7912 - accuracy: 0.7339 - val_loss: 1.0316 - val_accuracy: 0.6316\n","Epoch 10/100\n","19/19 - 43s - loss: 0.7456 - accuracy: 0.7223 - val_loss: 1.0640 - val_accuracy: 0.6118\n","Epoch 11/100\n","19/19 - 44s - loss: 0.6025 - accuracy: 0.7702 - val_loss: 0.9718 - val_accuracy: 0.6842\n","Epoch 12/100\n","19/19 - 44s - loss: 0.5256 - accuracy: 0.8182 - val_loss: 1.1370 - val_accuracy: 0.6118\n","Epoch 13/100\n","19/19 - 44s - loss: 0.4473 - accuracy: 0.8281 - val_loss: 1.2574 - val_accuracy: 0.6513\n","Epoch 14/100\n","19/19 - 44s - loss: 0.2971 - accuracy: 0.8926 - val_loss: 1.5838 - val_accuracy: 0.6250\n","Epoch 15/100\n","19/19 - 44s - loss: 0.5021 - accuracy: 0.8281 - val_loss: 1.3197 - val_accuracy: 0.6711\n","Epoch 16/100\n","19/19 - 44s - loss: 0.2660 - accuracy: 0.9124 - val_loss: 1.3693 - val_accuracy: 0.6447\n","Epoch 17/100\n","19/19 - 44s - loss: 0.2281 - accuracy: 0.9289 - val_loss: 1.5017 - val_accuracy: 0.6974\n","Epoch 18/100\n","19/19 - 44s - loss: 0.1834 - accuracy: 0.9306 - val_loss: 1.1874 - val_accuracy: 0.6908\n","Epoch 19/100\n","19/19 - 44s - loss: 0.0911 - accuracy: 0.9719 - val_loss: 1.7835 - val_accuracy: 0.7237\n","Epoch 20/100\n","19/19 - 44s - loss: 0.0869 - accuracy: 0.9769 - val_loss: 1.4953 - val_accuracy: 0.7039\n","Epoch 21/100\n","19/19 - 44s - loss: 0.0411 - accuracy: 0.9917 - val_loss: 2.0460 - val_accuracy: 0.6513\n","Epoch 22/100\n","19/19 - 44s - loss: 0.0401 - accuracy: 0.9884 - val_loss: 1.7670 - val_accuracy: 0.6908\n","Epoch 23/100\n","19/19 - 44s - loss: 0.0232 - accuracy: 0.9934 - val_loss: 2.4632 - val_accuracy: 0.6908\n","Epoch 24/100\n","19/19 - 44s - loss: 0.0296 - accuracy: 0.9884 - val_loss: 1.6327 - val_accuracy: 0.7105\n","Epoch 25/100\n","19/19 - 44s - loss: 0.0498 - accuracy: 0.9851 - val_loss: 1.9045 - val_accuracy: 0.6908\n","Epoch 26/100\n","19/19 - 44s - loss: 0.0784 - accuracy: 0.9686 - val_loss: 2.0456 - val_accuracy: 0.6513\n","Epoch 27/100\n","19/19 - 44s - loss: 0.0983 - accuracy: 0.9719 - val_loss: 1.9808 - val_accuracy: 0.7105\n","Epoch 28/100\n","19/19 - 44s - loss: 0.2532 - accuracy: 0.9190 - val_loss: 1.5469 - val_accuracy: 0.6382\n","Epoch 29/100\n","19/19 - 44s - loss: 0.1669 - accuracy: 0.9405 - val_loss: 1.5698 - val_accuracy: 0.7237\n","Epoch 30/100\n","19/19 - 44s - loss: 0.0985 - accuracy: 0.9636 - val_loss: 1.4537 - val_accuracy: 0.6579\n","Epoch 31/100\n","19/19 - 44s - loss: 0.0296 - accuracy: 0.9917 - val_loss: 2.0890 - val_accuracy: 0.6711\n","Epoch 32/100\n","19/19 - 44s - loss: 0.0528 - accuracy: 0.9785 - val_loss: 2.2487 - val_accuracy: 0.6513\n","Epoch 33/100\n","19/19 - 44s - loss: 0.0397 - accuracy: 0.9884 - val_loss: 1.7883 - val_accuracy: 0.7171\n","Epoch 34/100\n","19/19 - 44s - loss: 0.0215 - accuracy: 0.9950 - val_loss: 1.9468 - val_accuracy: 0.6974\n","Epoch 35/100\n","19/19 - 44s - loss: 0.0142 - accuracy: 0.9950 - val_loss: 2.0165 - val_accuracy: 0.6908\n","Epoch 36/100\n","19/19 - 44s - loss: 0.0192 - accuracy: 0.9950 - val_loss: 1.9828 - val_accuracy: 0.6711\n","Epoch 37/100\n","19/19 - 44s - loss: 0.0165 - accuracy: 0.9934 - val_loss: 1.7613 - val_accuracy: 0.6908\n","Epoch 38/100\n","19/19 - 44s - loss: 0.0122 - accuracy: 0.9950 - val_loss: 1.8590 - val_accuracy: 0.6776\n","Epoch 39/100\n","19/19 - 44s - loss: 0.0129 - accuracy: 0.9983 - val_loss: 2.0182 - val_accuracy: 0.6974\n","Epoch 40/100\n","19/19 - 44s - loss: 0.0072 - accuracy: 0.9983 - val_loss: 1.9314 - val_accuracy: 0.7434\n","Epoch 41/100\n","19/19 - 44s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.7171\n","Epoch 42/100\n","19/19 - 44s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9599 - val_accuracy: 0.7632\n","Epoch 43/100\n","19/19 - 44s - loss: 4.8040e-04 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.7632\n","Epoch 44/100\n","19/19 - 44s - loss: 6.3140e-04 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.7763\n","Epoch 45/100\n","19/19 - 44s - loss: 3.6849e-04 - accuracy: 1.0000 - val_loss: 2.3058 - val_accuracy: 0.7697\n","Epoch 46/100\n","19/19 - 44s - loss: 2.0152e-04 - accuracy: 1.0000 - val_loss: 2.3688 - val_accuracy: 0.7697\n","Epoch 47/100\n","19/19 - 44s - loss: 8.3756e-05 - accuracy: 1.0000 - val_loss: 2.3945 - val_accuracy: 0.7632\n","Epoch 48/100\n","19/19 - 44s - loss: 6.9600e-05 - accuracy: 1.0000 - val_loss: 2.4320 - val_accuracy: 0.7632\n","Epoch 49/100\n","19/19 - 44s - loss: 1.8582e-04 - accuracy: 1.0000 - val_loss: 2.4594 - val_accuracy: 0.7566\n","Epoch 50/100\n","19/19 - 44s - loss: 5.4797e-05 - accuracy: 1.0000 - val_loss: 2.4893 - val_accuracy: 0.7500\n","Epoch 51/100\n","19/19 - 44s - loss: 1.2420e-04 - accuracy: 1.0000 - val_loss: 2.5685 - val_accuracy: 0.7632\n","Epoch 52/100\n","19/19 - 44s - loss: 4.5008e-04 - accuracy: 1.0000 - val_loss: 2.7068 - val_accuracy: 0.7434\n","Epoch 53/100\n","19/19 - 44s - loss: 1.9435e-04 - accuracy: 1.0000 - val_loss: 2.6577 - val_accuracy: 0.7566\n","Epoch 54/100\n","19/19 - 44s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4690 - val_accuracy: 0.7697\n","Epoch 55/100\n","19/19 - 44s - loss: 3.2184e-04 - accuracy: 1.0000 - val_loss: 2.3547 - val_accuracy: 0.7171\n","Epoch 56/100\n","19/19 - 44s - loss: 1.4588e-04 - accuracy: 1.0000 - val_loss: 2.3819 - val_accuracy: 0.7171\n","Epoch 57/100\n","19/19 - 44s - loss: 3.4514e-04 - accuracy: 1.0000 - val_loss: 2.4223 - val_accuracy: 0.7368\n","Epoch 58/100\n","19/19 - 44s - loss: 1.0318e-04 - accuracy: 1.0000 - val_loss: 2.4696 - val_accuracy: 0.7500\n","Epoch 59/100\n","19/19 - 44s - loss: 4.2780e-05 - accuracy: 1.0000 - val_loss: 2.4988 - val_accuracy: 0.7434\n","Epoch 60/100\n","19/19 - 44s - loss: 4.2396e-05 - accuracy: 1.0000 - val_loss: 2.5221 - val_accuracy: 0.7434\n","Epoch 61/100\n","19/19 - 44s - loss: 5.0324e-05 - accuracy: 1.0000 - val_loss: 2.5507 - val_accuracy: 0.7434\n","Epoch 62/100\n","19/19 - 44s - loss: 3.7584e-05 - accuracy: 1.0000 - val_loss: 2.5795 - val_accuracy: 0.7434\n","Epoch 63/100\n","19/19 - 44s - loss: 6.1591e-05 - accuracy: 1.0000 - val_loss: 2.6040 - val_accuracy: 0.7434\n","Epoch 64/100\n","19/19 - 44s - loss: 3.0496e-05 - accuracy: 1.0000 - val_loss: 2.6214 - val_accuracy: 0.7434\n","Epoch 65/100\n","19/19 - 44s - loss: 2.6291e-05 - accuracy: 1.0000 - val_loss: 2.6380 - val_accuracy: 0.7434\n","Epoch 66/100\n","19/19 - 43s - loss: 2.6675e-05 - accuracy: 1.0000 - val_loss: 2.6553 - val_accuracy: 0.7434\n","Epoch 67/100\n","19/19 - 43s - loss: 4.4550e-05 - accuracy: 1.0000 - val_loss: 2.6831 - val_accuracy: 0.7368\n","Epoch 68/100\n","19/19 - 43s - loss: 3.2106e-05 - accuracy: 1.0000 - val_loss: 2.7064 - val_accuracy: 0.7368\n","Epoch 69/100\n","19/19 - 43s - loss: 3.2736e-05 - accuracy: 1.0000 - val_loss: 2.7213 - val_accuracy: 0.7368\n","Epoch 70/100\n","19/19 - 43s - loss: 2.5698e-05 - accuracy: 1.0000 - val_loss: 2.7343 - val_accuracy: 0.7368\n","Epoch 71/100\n","19/19 - 43s - loss: 1.3775e-05 - accuracy: 1.0000 - val_loss: 2.7479 - val_accuracy: 0.7368\n","Epoch 72/100\n","19/19 - 43s - loss: 5.6731e-05 - accuracy: 1.0000 - val_loss: 2.7734 - val_accuracy: 0.7303\n","Epoch 73/100\n","19/19 - 43s - loss: 2.9368e-05 - accuracy: 1.0000 - val_loss: 2.7920 - val_accuracy: 0.7303\n","Epoch 74/100\n","19/19 - 43s - loss: 1.2661e-05 - accuracy: 1.0000 - val_loss: 2.8066 - val_accuracy: 0.7303\n","Epoch 75/100\n","19/19 - 43s - loss: 7.6133e-05 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.7434\n","Epoch 76/100\n","19/19 - 43s - loss: 2.8296e-05 - accuracy: 1.0000 - val_loss: 2.8322 - val_accuracy: 0.7632\n","Epoch 77/100\n","19/19 - 43s - loss: 5.8419e-04 - accuracy: 1.0000 - val_loss: 3.7519 - val_accuracy: 0.5987\n","Epoch 78/100\n","19/19 - 43s - loss: 0.7677 - accuracy: 0.7455 - val_loss: 1.2718 - val_accuracy: 0.5132\n","Epoch 79/100\n","19/19 - 43s - loss: 0.8417 - accuracy: 0.6826 - val_loss: 1.3024 - val_accuracy: 0.5592\n","Epoch 80/100\n","19/19 - 43s - loss: 0.5711 - accuracy: 0.7901 - val_loss: 1.4127 - val_accuracy: 0.6184\n","Epoch 81/100\n","19/19 - 43s - loss: 0.3061 - accuracy: 0.8826 - val_loss: 1.8369 - val_accuracy: 0.6118\n","Epoch 82/100\n","19/19 - 43s - loss: 0.1507 - accuracy: 0.9521 - val_loss: 1.7321 - val_accuracy: 0.5658\n","Epoch 83/100\n","19/19 - 43s - loss: 0.0860 - accuracy: 0.9686 - val_loss: 2.3185 - val_accuracy: 0.6579\n","Epoch 84/100\n","19/19 - 43s - loss: 0.3101 - accuracy: 0.9008 - val_loss: 1.7494 - val_accuracy: 0.5461\n","Epoch 85/100\n","19/19 - 43s - loss: 0.2960 - accuracy: 0.8975 - val_loss: 1.2714 - val_accuracy: 0.7105\n","Epoch 86/100\n","19/19 - 43s - loss: 0.0932 - accuracy: 0.9818 - val_loss: 1.9870 - val_accuracy: 0.5461\n","Epoch 87/100\n","19/19 - 43s - loss: 0.0520 - accuracy: 0.9884 - val_loss: 2.1689 - val_accuracy: 0.7237\n","Epoch 88/100\n","19/19 - 43s - loss: 0.0290 - accuracy: 0.9901 - val_loss: 1.9902 - val_accuracy: 0.7237\n","Epoch 89/100\n","19/19 - 43s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.8785 - val_accuracy: 0.7039\n","Epoch 90/100\n","19/19 - 43s - loss: 0.0107 - accuracy: 0.9967 - val_loss: 2.1723 - val_accuracy: 0.7368\n","Epoch 91/100\n","19/19 - 43s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.0279 - val_accuracy: 0.8026\n","Epoch 92/100\n","19/19 - 43s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.1333 - val_accuracy: 0.7763\n","Epoch 93/100\n","19/19 - 43s - loss: 6.3960e-04 - accuracy: 1.0000 - val_loss: 2.3904 - val_accuracy: 0.7697\n","Epoch 94/100\n","19/19 - 43s - loss: 7.2005e-04 - accuracy: 1.0000 - val_loss: 2.3808 - val_accuracy: 0.7895\n","Epoch 95/100\n","19/19 - 43s - loss: 2.8710e-04 - accuracy: 1.0000 - val_loss: 2.4174 - val_accuracy: 0.7961\n","Epoch 96/100\n","19/19 - 43s - loss: 1.9123e-04 - accuracy: 1.0000 - val_loss: 2.4691 - val_accuracy: 0.7895\n","Epoch 97/100\n","19/19 - 43s - loss: 4.6816e-04 - accuracy: 1.0000 - val_loss: 2.5089 - val_accuracy: 0.7829\n","Epoch 98/100\n","19/19 - 43s - loss: 1.1412e-04 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.7829\n","Epoch 99/100\n","19/19 - 43s - loss: 2.1243e-04 - accuracy: 1.0000 - val_loss: 2.5487 - val_accuracy: 0.7829\n","Epoch 100/100\n","19/19 - 43s - loss: 2.8487e-04 - accuracy: 1.0000 - val_loss: 2.4957 - val_accuracy: 0.7763\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f5712b05f28>"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"sYSDseDyIk1m","executionInfo":{"status":"ok","timestamp":1602241714386,"user_tz":-330,"elapsed":4432018,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"43aedf89-51d1-48c7-a396-4440544edc85","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#load the checkpoint from here\n","\n","#get the latest checkpoint file\n","checkpoint_dir = os.path.dirname(\"/content/best.ckpt\")\n","latest = tf.train.latest_checkpoint(checkpoint_dir)\n","\n","#Create a new model instance\n","model_latest_checkpoint = model\n","model_latest_checkpoint.summary()\n","# Load the previously saved weights\n","model_latest_checkpoint.load_weights(latest)\n","# Re-evaluate the model\n","loss, acc = model_latest_checkpoint.evaluate(X_test,  Y_test, verbose=2)\n","print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 288, 432, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 288, 432, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 288, 432, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 144, 216, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 144, 216, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 144, 216, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 72, 108, 128)      0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 72, 108, 256)      295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 36, 54, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 36, 54, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 36, 54, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 36, 54, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 18, 27, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 18, 27, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 9, 13, 512)        0         \n","_________________________________________________________________\n","averagepool_last (AveragePoo (None, 2, 3, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3072)              0         \n","_________________________________________________________________\n","dense_512 (Dense)            (None, 512)               1573376   \n","_________________________________________________________________\n","dense_128 (Dense)            (None, 128)               65664     \n","_________________________________________________________________\n","dropout_last (Dropout)       (None, 128)               0         \n","_________________________________________________________________\n","output (Dense)               (None, 5)                 645       \n","=================================================================\n","Total params: 16,354,373\n","Trainable params: 16,354,373\n","Non-trainable params: 0\n","_________________________________________________________________\n","5/5 - 2s - loss: 2.0279 - accuracy: 0.8026\n","Restored model, accuracy: 80.26%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d7X2FFCuIOWr"},"source":["#copy of 68 features code\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5hGMy3xJci0H"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZfKDJzju-g1o"},"source":["import os\n","def get_file_length(file_path):\n","    path, dirs, files = next(os.walk(file_path))\n","    count = len(files)\n","    #print(count)\n","    return count\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPODk5NO-g1t"},"source":["def get_labels(c1,c2,c3,c4,c5):\n","    labels = np.zeros((c1,1))\n","    labels = np.concatenate((labels,np.ones((c2,1))))\n","    labels = np.concatenate((labels,2*np.ones((c3,1))))\n","    labels = np.concatenate((labels,3*np.ones((c4,1))))\n","    labels = np.concatenate((labels,4*np.ones((c5,1))))\n","    #print(labels.shape)\n","    return labels\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FBuvXP9b-g1y"},"source":["# File Length \n","belly_pain_count_test = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/test/belly_pain')\n","burping_count_test = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/test/burping')\n","discomfort_count_test = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/test/discomfort')\n","hungry_count_test = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/test/hungry')\n","tired_count_test = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/test/tired')\n","belly_pain_count_train = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/train/belly_pain')\n","burping_count_train = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/train/burping')\n","discomfort_count_train = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/train/discomfort')\n","hungry_count_train = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/train/hungry')\n","tired_count_train = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/train/tired')\n","belly_pain_count_valid = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/val/belly_pain')\n","burping_count_valid = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/val/burping')\n","discomfort_count_valid = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/val/discomfort')\n","hungry_count_valid = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/val/hungry')\n","tired_count_valid = get_file_length(r'/content/drive/My Drive/Baby Cry/68features/val/tired')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eN9UKo17-g12"},"source":["labels_test = get_labels(belly_pain_count_test , burping_count_test , discomfort_count_test , hungry_count_test , tired_count_test)\n","labels_train = get_labels(belly_pain_count_train , burping_count_train , discomfort_count_train , hungry_count_train , tired_count_train)\n","labels_val = get_labels(belly_pain_count_valid , burping_count_valid , discomfort_count_valid , hungry_count_valid , tired_count_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYVF4_EI-g17","executionInfo":{"status":"ok","timestamp":1602241726808,"user_tz":-330,"elapsed":4333071,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"a2204de6-b9f3-4b9d-bac8-c61af84ca97d","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["print(labels_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(152, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kQIIGhyr-g2C","executionInfo":{"status":"ok","timestamp":1602241726808,"user_tz":-330,"elapsed":4331720,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"a7857b4b-8600-42a1-fafd-04fa09b93ccc","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["labels_train = np.append(labels_train,labels_val)\n","\n","print(labels_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JF7Mlujl-g2I","executionInfo":{"status":"ok","timestamp":1602241726810,"user_tz":-330,"elapsed":4330360,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"47464741-60f8-4b9b-dcfb-a2207c2a58c1","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["labels_train = np.reshape(labels_train,(labels_train.shape[0],1))\n","print(labels_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9pLQSeev-g2O","executionInfo":{"status":"ok","timestamp":1602243009934,"user_tz":-330,"elapsed":411963,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"f4060cba-610a-4cd5-bda0-39d27228ac22","colab":{"base_uri":"https://localhost:8080/","height":318}},"source":["#from python_speech_features import mfcc\n","#from python_speech_features import logfeatures\n","import scipy.io.wavfile as wav\n","import numpy\n","import os\n","import csv\n","import numpy as np\n","\n","\n","def get_features_array(dir):\n","    features = np.zeros((68,199,1))\n","    for folder in os.listdir(dir):\n","        folder_path = os.path.join(dir,folder)\n","        i = 0\n","        for filename in os.listdir(folder_path):\n","            if filename.endswith('.csv'):\n","                i = i+1\n","                file_path = os.path.join(folder_path,filename)\n","                temp = np.genfromtxt(file_path, delimiter=\",\", skip_header = False)\n","                temp  = np.reshape(temp,(temp.shape[0],temp.shape[1],1))\n","                #print(temp.shape)\n","                features = np.append(features,temp,axis = 2)\n","                #print(mfcc.shape)\n","        print(str(folder)+ ' has ' + str(i) + ' files ' )\n","    features = np.reshape(features,(features.shape[2],features.shape[0],features.shape[1]))\n","    features = np.delete(features,0,axis = 0)\n","    return(features)\n","\n","features_test = get_features_array(r'/content/drive/My Drive/Baby Cry/68features/test')\n","print(features_test.shape)\n","features_train = get_features_array(r'/content/drive/My Drive/Baby Cry/68features/train')\n","print(features_train.shape)\n","features_val = get_features_array(r'/content/drive/My Drive/Baby Cry/68features/val')\n","print(features_val.shape)    \n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["belly_pain has 16 files \n","burping has 8 files \n","discomfort has 27 files \n","hungry has 77 files \n","tired has 24 files \n","(152, 68, 199)\n","belly_pain has 48 files \n","burping has 24 files \n","discomfort has 81 files \n","hungry has 229 files \n","tired has 72 files \n","(454, 68, 199)\n","belly_pain has 16 files \n","burping has 8 files \n","discomfort has 27 files \n","hungry has 76 files \n","tired has 24 files \n","(151, 68, 199)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uE92L5qaiv3"},"source":["test_array = np.transpose(features_test, (0, 2, 1))\n","#print(test_array.shape)\n","train_array = np.transpose(features_train, (0, 2, 1))\n","valid_array = np.transpose(features_val, (0, 2, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QCsal8bM-g2T","executionInfo":{"status":"ok","timestamp":1602243014551,"user_tz":-330,"elapsed":1295,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"28dc36ca-5bf9-482a-9c14-3c5d5238cb10","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["features_train = np.append(train_array,valid_array,axis = 0)\n","print(features_train.shape)\n","features_test = test_array"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 199, 68)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DGHEFrR6-g2Y","executionInfo":{"status":"ok","timestamp":1602243016034,"user_tz":-330,"elapsed":1467,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"94394055-7ead-440b-ca00-23049fcf55c4","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["flatten_train = features_train.reshape(features_train.shape[0],-1)\n","flatten_test = features_test.reshape(features_test.shape[0],-1)\n","\n","print(flatten_train.shape)\n","print(flatten_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 13532)\n","(152, 13532)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N3AIRlL5jIVG"},"source":["# spectrogram features in sequence belly_pain ,burping, hungry, tired, discomfort\n","# changing 68 features to this sequence as orignal sequence is belly_pain ,burping, discomfort, hungry, tired\n","# test_data has belly_pain =16, burping = 8, discomfort = 27,hungry = 77, tired = 24\n","# train data has belly_pain = 48, burping = 24 , discomfort = 81 , hungry = 229, tired = 72 \n","# valid has belly_pain = 16, burping = 8 , discomfort = 27 ,hungry = 76 ,tired = 24 \n","\n","correct_flatten_train = np.concatenate((flatten_train[0:48],flatten_train[48:72], flatten_train[153:382],flatten_train[382:454], flatten_train[72:153],flatten_train[454:470],flatten_train[470:478],flatten_train[505:581],flatten_train[581:605],flatten_train[478:505]),axis = 0)\n","correct_flatten_test = np.concatenate((flatten_test[0:16],flatten_test[16:24],flatten_test[51:128],flatten_test[128:152],flatten_test[24:51]),axis = 0)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8G8ujd8IJ8eQ","executionInfo":{"status":"ok","timestamp":1602244291793,"user_tz":-330,"elapsed":1279,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"aea0c044-897c-46e9-8c1d-58f5b14f7556","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(correct_flatten_train.shape)\n","print(correct_flatten_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 13532)\n","(152, 13532)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CxBWYr7iKf4N"},"source":["\n","#freeze layers of vgg16\n","\n","for layer in model_latest_checkpoint.layers:\n","  layer.trainable = False\n","\n","\n","intermediate_output = model_latest_checkpoint.get_layer('flatten').output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"COayTnrlaQYj","executionInfo":{"status":"ok","timestamp":1602244299652,"user_tz":-330,"elapsed":947,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"7ad8736c-2600-43e8-cc08-942d4071cbe7","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["print(intermediate_output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensor(\"flatten/Reshape_1:0\", shape=(None, 3072), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LiSZMJOdTAko","executionInfo":{"status":"ok","timestamp":1602244302698,"user_tz":-330,"elapsed":1578,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"558b2f08-0063-4b51-ad55-46aa9ac6e863","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#convert array to keras tensor\n","\n","tensor_train = Input(shape=(flatten_train.shape[1],))\n"," \n","#print(tensor_train)\n","\n","#merge layer output with this array(keras tensor)\n","merged_output = tf.keras.layers.Concatenate(axis=1)([intermediate_output, tensor_train])\n","\n","x = Dense(512, activation=\"relu\",name = 'MLP_512')(merged_output)\n","x = Dense(128, activation=\"relu\",name = 'MLP_128')(x)   # we can experiment with more dense layers if output of average pooling layer is too big\n","x = Dropout(0.3,name = 'dropout_MLP')(x)\n","out_mlp = Dense(5, activation=\"softmax\",name = 'output')(x)  # we have 5 classes\n","\n","#build the mlp model\n","second_model = Model(inputs = tensor_train, outputs=tensor_train)\n","\n","total_model = Model(inputs=[model_latest_checkpoint.input, second_model.input], outputs=out_mlp)\n","opt=Adam(lr=1e-4)\n","total_model.compile(loss='categorical_crossentropy', optimizer=opt,\tmetrics=[\"accuracy\"])\n","total_model.summary()\n","#Add 68 feature + MPL model at end "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_11\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 288, 432, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 288, 432, 64) 1792        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 288, 432, 64) 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 144, 216, 64) 0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 144, 216, 128 73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 144, 216, 128 147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 72, 108, 128) 0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 72, 108, 256) 295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 72, 108, 256) 590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv3 (Conv2D)           (None, 72, 108, 256) 590080      block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 36, 54, 256)  0           block3_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv1 (Conv2D)           (None, 36, 54, 512)  1180160     block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","block4_conv2 (Conv2D)           (None, 36, 54, 512)  2359808     block4_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block4_conv3 (Conv2D)           (None, 36, 54, 512)  2359808     block4_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 18, 27, 512)  0           block4_conv3[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv1 (Conv2D)           (None, 18, 27, 512)  2359808     block4_pool[0][0]                \n","__________________________________________________________________________________________________\n","block5_conv2 (Conv2D)           (None, 18, 27, 512)  2359808     block5_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block5_conv3 (Conv2D)           (None, 18, 27, 512)  2359808     block5_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block5_pool (MaxPooling2D)      (None, 9, 13, 512)   0           block5_conv3[0][0]               \n","__________________________________________________________________________________________________\n","averagepool_last (AveragePoolin (None, 2, 3, 512)    0           block5_pool[0][0]                \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 3072)         0           averagepool_last[0][0]           \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 13532)]      0                                            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 16604)        0           flatten[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","MLP_512 (Dense)                 (None, 512)          8501760     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","MLP_128 (Dense)                 (None, 128)          65664       MLP_512[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_MLP (Dropout)           (None, 128)          0           MLP_128[0][0]                    \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 5)            645         dropout_MLP[0][0]                \n","==================================================================================================\n","Total params: 23,282,757\n","Trainable params: 8,568,069\n","Non-trainable params: 14,714,688\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kiDq1NPidXYX"},"source":["import tensorflow as tf\n","#callback for best Val Accuracy\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=\"/content/total_best.ckpt\",\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ayAfPhUN2oM","executionInfo":{"status":"ok","timestamp":1602244314798,"user_tz":-330,"elapsed":1221,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"e6973692-00a2-4059-abff-7cd7ae4d4ca0","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(X_train.shape)\n","print(correct_flatten_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(605, 288, 432, 3)\n","(605, 13532)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lw6HMgSdrVDM","executionInfo":{"status":"ok","timestamp":1602245369530,"user_tz":-330,"elapsed":300225,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"3acc8881-a334-41d4-aad1-36eab9977ae5","colab":{"base_uri":"https://localhost:8080/","height":702}},"source":["#total_model\n","total_model.fit([X_train,correct_flatten_train], Y_train, batch_size=32,\tvalidation_data=([X_test,correct_flatten_test], Y_test),\tepochs=20, verbose=2, callbacks=[model_checkpoint_callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","19/19 - 15s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8684\n","Epoch 2/20\n","19/19 - 15s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.8750\n","Epoch 3/20\n","19/19 - 14s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7721 - val_accuracy: 0.8553\n","Epoch 4/20\n","19/19 - 14s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7722 - val_accuracy: 0.8553\n","Epoch 5/20\n","19/19 - 14s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7813 - val_accuracy: 0.8553\n","Epoch 6/20\n","19/19 - 14s - loss: 9.1024e-04 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.8684\n","Epoch 7/20\n","19/19 - 14s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8014 - val_accuracy: 0.8553\n","Epoch 8/20\n","19/19 - 14s - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.8736 - val_accuracy: 0.8553\n","Epoch 9/20\n","19/19 - 14s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.8618\n","Epoch 10/20\n","19/19 - 14s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8553\n","Epoch 11/20\n","19/19 - 14s - loss: 7.1226e-04 - accuracy: 1.0000 - val_loss: 0.8587 - val_accuracy: 0.8553\n","Epoch 12/20\n","19/19 - 14s - loss: 5.8371e-04 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.8553\n","Epoch 13/20\n","19/19 - 14s - loss: 8.1302e-04 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.8553\n","Epoch 14/20\n","19/19 - 14s - loss: 7.9144e-04 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.8487\n","Epoch 15/20\n","19/19 - 14s - loss: 8.3556e-04 - accuracy: 1.0000 - val_loss: 0.8643 - val_accuracy: 0.8618\n","Epoch 16/20\n","19/19 - 14s - loss: 4.7402e-04 - accuracy: 1.0000 - val_loss: 0.8756 - val_accuracy: 0.8618\n","Epoch 17/20\n","19/19 - 14s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8686 - val_accuracy: 0.8487\n","Epoch 18/20\n","19/19 - 14s - loss: 6.3124e-04 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.8487\n","Epoch 19/20\n","19/19 - 14s - loss: 3.6189e-04 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.8487\n","Epoch 20/20\n","19/19 - 14s - loss: 5.2702e-04 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.8487\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f57116eada0>"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"x2A7BmVoP7BE","executionInfo":{"status":"ok","timestamp":1602245375187,"user_tz":-330,"elapsed":5645,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"3b962342-cac0-414b-ff0e-b6ba722d6fd4","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#load the checkpoint from here\n","\n","#get the latest checkpoint file\n","checkpoint_dir = os.path.dirname('/content/total_best.ckpt')\n","latest = tf.train.latest_checkpoint(checkpoint_dir)\n","\n","#Create a new model instance\n","model_latest_checkpoint = total_model\n","#model_latest_checkpoint.summary()\n","# Load the previously saved weights\n","model_latest_checkpoint.load_weights(latest)\n","# Re-evaluate the model\n","loss, acc = model_latest_checkpoint.evaluate([X_test,correct_flatten_test],  Y_test, verbose=2)\n","print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5/5 - 2s - loss: 0.7604 - accuracy: 0.8750\n","Restored model, accuracy: 87.50%\n"],"name":"stdout"}]}]}