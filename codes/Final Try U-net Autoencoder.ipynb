{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Try U-net Autoencoder.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-wlvam2Ezdzx","executionInfo":{"status":"ok","timestamp":1602419078417,"user_tz":-60,"elapsed":1389,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"cda6f618-a268-4cfa-d459-ca89c35af8f7","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sTnok07TZF21"},"source":["#Sahil GDrive\n","import numpy as np\n","\n","train_1 = np.load(r'/content/drive/My Drive/Baby Cry/stratified k fold data/train_5.npy')\n","test_1 = np.load(r'/content/drive/My Drive/Baby Cry/stratified k fold data/test_5.npy')\n","\n","train_lab_1 = np.load(r'/content/drive/My Drive/Baby Cry/stratified k fold data/train_lab_5.npy')\n","test_lab_1 = np.load(r'/content/drive/My Drive/Baby Cry/stratified k fold data/test_lab_5.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zQo2LkpRjpb"},"source":["import numpy as np\n","\n","train_1 = np.load(r'/content/drive/My Drive/stratified k fold data/train_5.npy')\n","test_1 = np.load(r'/content/drive/My Drive/stratified k fold data/test_5.npy')\n","\n","train_lab_1 = np.load(r'/content/drive/My Drive/stratified k fold data/train_lab_5.npy')\n","test_lab_1 = np.load(r'/content/drive/My Drive/stratified k fold data/test_lab_5.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aG6Sz2sHk99z","executionInfo":{"status":"ok","timestamp":1602410080930,"user_tz":-330,"elapsed":41765,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"4deb5875-e7a5-421e-d0f0-050696e0d574","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten,Reshape,Cropping2D,Conv2DTranspose,concatenate,BatchNormalization,Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.initializers import orthogonal\n","from tensorflow.keras.optimizers import Adam, SGD\n","\n","input_file = Input(shape=(288,432, 3))\n","\n","def Contract(x, filters, kernel , strides, padding, block_id, kernel_init=orthogonal()):\n","  prefix = f'block_{block_id}_'\n","  x = tf.keras.layers.Conv2D(filters= filters,kernel_size = kernel, strides = strides, kernel_initializer=kernel_init,\n","                             activation = None , padding = padding, name= prefix+'conv1_contract')(x)                           \n","  x = tf.keras.layers.Conv2D(filters= filters,kernel_size = kernel, strides = strides, kernel_initializer=kernel_init,\n","                             activation = None, padding = padding,  name= prefix+'conv2_contract')(x)\n","  x = tf.keras.layers.BatchNormalization(name=prefix+'conv_bn_contract')(x)\n","  x = tf.keras.layers.Dropout(0.2 ,name = prefix +'dropout_contract')(x)\n","  x = tf.keras.layers.LeakyReLU(name=prefix+'lrelu_contract')(x)\n","  return x\n","\n","def Expand(x , y , filters, kernel, trans_kernel,strides, padding, block_id, kernel_init=orthogonal()):\n","  prefix = f'block_{block_id}_'\n","  x = tf.keras.layers.Conv2DTranspose(filters,trans_kernel,strides = strides,kernel_initializer = kernel_init, \n","                                      padding = padding,name = prefix + 'trans_conv2d_expand')(x)\n","  x = tf.keras.layers.concatenate([x,y],name = prefix + 'concatenate_expand')\n","  x = tf.keras.layers.Conv2D(filters,kernel_size = kernel,activation = None ,kernel_initializer = kernel_init,\n","                             padding = padding,name = prefix + 'conv2d_1_expand')(x)\n","  x = tf.keras.layers.Conv2D(filters,kernel_size=kernel,activation = None ,kernel_initializer = kernel_init,\n","                             padding = padding,name = prefix + 'conv2d_2_expand')(x)\n","  x = tf.keras.layers.BatchNormalization(name=prefix+'conv_bn_expand')(x)\n","  x = tf.keras.layers.LeakyReLU(name=prefix+'lrelu_expand')(x)\n","  x = tf.keras.layers.Dropout(0.2, name=prefix+'dropout_expand')((x))\n","  return x\n","\n","\n","def U_net_arch(input_shape):\n","  inputs = Input(shape=input_shape)\n","  \n","  #contracting path\n","  \n","  c1 = Contract(inputs, 4, 3 , strides = 1, padding='same', block_id=1)\n","  p1 = tf.keras.layers.MaxPooling2D((2,2),name = 'block_1_max_pool')(c1)\n","\n","  c2 = Contract(p1, 8, 3 , strides = 1, padding='same', block_id=2)\n","  p2 = tf.keras.layers.MaxPooling2D((2,2),name = 'block_2_max_pool')(c2)\n","\n","  c3 = Contract(p2, 16, 3 , strides = 1, padding='same', block_id=3)\n","  p3 = tf.keras.layers.MaxPooling2D((2,2),name = 'block_3_max_pool')(c3)\n","\n","  c4 = Contract(p3, 32, 3 , strides = 1, padding='same', block_id=4)\n","  p4 = tf.keras.layers.MaxPooling2D((2,2),name = 'block_4_max_pool')(c4)\n","\n","  c5 = Contract(p4, 64, 3 , strides = 1, padding='same', block_id=5)\n","\n","  #Dense layers to reduce the bottleneck features\n","  \n","  x = Flatten(name = 'flatten_bottleneck')(c5)\n","\n","  \n","  c5 = Reshape((18,27 , 64))(x)\n","  \n","  #expanding path\n","  \n","  c6 = Expand(c5, c4, 32, 3 , (2,2), strides = (2,2), padding='same', block_id = 6)\n","  \n","  c7 = Expand(c6, c3, 16, 3 , (2,2), strides = (2,2), padding='same', block_id = 7)\n","  \n","  c8 = Expand(c7, c2, 8, 3 , (2,2), strides = (2,2), padding='same', block_id = 8)\n","\n","  c9 = Expand(c8, c1, 4, 3 , (2,2), strides = (2,2), padding='same', block_id = 9)\n","  \n","  outputs = tf.keras.layers.Conv2D(3,(1,1),activation = 'sigmoid')(c9)\n","  \n","  return Model(inputs=inputs, outputs=outputs) \n","\n","input_shape = (288,432)\n","U_net = U_net_arch((*input_shape,3))\n","opt=Adam(lr=1e-4)\n","U_net.compile(optimizer=opt, loss='mse') #msse\n","\n","U_net.summary()\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 288, 432, 3) 0                                            \n","__________________________________________________________________________________________________\n","block_1_conv1_contract (Conv2D) (None, 288, 432, 4)  112         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","block_1_conv2_contract (Conv2D) (None, 288, 432, 4)  148         block_1_conv1_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_1_conv_bn_contract (Batch (None, 288, 432, 4)  16          block_1_conv2_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_1_dropout_contract (Dropo (None, 288, 432, 4)  0           block_1_conv_bn_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_1_lrelu_contract (LeakyRe (None, 288, 432, 4)  0           block_1_dropout_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_1_max_pool (MaxPooling2D) (None, 144, 216, 4)  0           block_1_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_2_conv1_contract (Conv2D) (None, 144, 216, 8)  296         block_1_max_pool[0][0]           \n","__________________________________________________________________________________________________\n","block_2_conv2_contract (Conv2D) (None, 144, 216, 8)  584         block_2_conv1_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_2_conv_bn_contract (Batch (None, 144, 216, 8)  32          block_2_conv2_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_2_dropout_contract (Dropo (None, 144, 216, 8)  0           block_2_conv_bn_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_2_lrelu_contract (LeakyRe (None, 144, 216, 8)  0           block_2_dropout_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_2_max_pool (MaxPooling2D) (None, 72, 108, 8)   0           block_2_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_3_conv1_contract (Conv2D) (None, 72, 108, 16)  1168        block_2_max_pool[0][0]           \n","__________________________________________________________________________________________________\n","block_3_conv2_contract (Conv2D) (None, 72, 108, 16)  2320        block_3_conv1_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_3_conv_bn_contract (Batch (None, 72, 108, 16)  64          block_3_conv2_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_3_dropout_contract (Dropo (None, 72, 108, 16)  0           block_3_conv_bn_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_3_lrelu_contract (LeakyRe (None, 72, 108, 16)  0           block_3_dropout_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_3_max_pool (MaxPooling2D) (None, 36, 54, 16)   0           block_3_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_4_conv1_contract (Conv2D) (None, 36, 54, 32)   4640        block_3_max_pool[0][0]           \n","__________________________________________________________________________________________________\n","block_4_conv2_contract (Conv2D) (None, 36, 54, 32)   9248        block_4_conv1_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_4_conv_bn_contract (Batch (None, 36, 54, 32)   128         block_4_conv2_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_4_dropout_contract (Dropo (None, 36, 54, 32)   0           block_4_conv_bn_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_4_lrelu_contract (LeakyRe (None, 36, 54, 32)   0           block_4_dropout_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_4_max_pool (MaxPooling2D) (None, 18, 27, 32)   0           block_4_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_5_conv1_contract (Conv2D) (None, 18, 27, 64)   18496       block_4_max_pool[0][0]           \n","__________________________________________________________________________________________________\n","block_5_conv2_contract (Conv2D) (None, 18, 27, 64)   36928       block_5_conv1_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_5_conv_bn_contract (Batch (None, 18, 27, 64)   256         block_5_conv2_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_5_dropout_contract (Dropo (None, 18, 27, 64)   0           block_5_conv_bn_contract[0][0]   \n","__________________________________________________________________________________________________\n","block_5_lrelu_contract (LeakyRe (None, 18, 27, 64)   0           block_5_dropout_contract[0][0]   \n","__________________________________________________________________________________________________\n","flatten_bottleneck (Flatten)    (None, 31104)        0           block_5_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 18, 27, 64)   0           flatten_bottleneck[0][0]         \n","__________________________________________________________________________________________________\n","block_6_trans_conv2d_expand (Co (None, 36, 54, 32)   8224        reshape[0][0]                    \n","__________________________________________________________________________________________________\n","block_6_concatenate_expand (Con (None, 36, 54, 64)   0           block_6_trans_conv2d_expand[0][0]\n","                                                                 block_4_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_6_conv2d_1_expand (Conv2D (None, 36, 54, 32)   18464       block_6_concatenate_expand[0][0] \n","__________________________________________________________________________________________________\n","block_6_conv2d_2_expand (Conv2D (None, 36, 54, 32)   9248        block_6_conv2d_1_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_6_conv_bn_expand (BatchNo (None, 36, 54, 32)   128         block_6_conv2d_2_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_6_lrelu_expand (LeakyReLU (None, 36, 54, 32)   0           block_6_conv_bn_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_6_dropout_expand (Dropout (None, 36, 54, 32)   0           block_6_lrelu_expand[0][0]       \n","__________________________________________________________________________________________________\n","block_7_trans_conv2d_expand (Co (None, 72, 108, 16)  2064        block_6_dropout_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_7_concatenate_expand (Con (None, 72, 108, 32)  0           block_7_trans_conv2d_expand[0][0]\n","                                                                 block_3_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_7_conv2d_1_expand (Conv2D (None, 72, 108, 16)  4624        block_7_concatenate_expand[0][0] \n","__________________________________________________________________________________________________\n","block_7_conv2d_2_expand (Conv2D (None, 72, 108, 16)  2320        block_7_conv2d_1_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_7_conv_bn_expand (BatchNo (None, 72, 108, 16)  64          block_7_conv2d_2_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_7_lrelu_expand (LeakyReLU (None, 72, 108, 16)  0           block_7_conv_bn_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_7_dropout_expand (Dropout (None, 72, 108, 16)  0           block_7_lrelu_expand[0][0]       \n","__________________________________________________________________________________________________\n","block_8_trans_conv2d_expand (Co (None, 144, 216, 8)  520         block_7_dropout_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_8_concatenate_expand (Con (None, 144, 216, 16) 0           block_8_trans_conv2d_expand[0][0]\n","                                                                 block_2_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_8_conv2d_1_expand (Conv2D (None, 144, 216, 8)  1160        block_8_concatenate_expand[0][0] \n","__________________________________________________________________________________________________\n","block_8_conv2d_2_expand (Conv2D (None, 144, 216, 8)  584         block_8_conv2d_1_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_8_conv_bn_expand (BatchNo (None, 144, 216, 8)  32          block_8_conv2d_2_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_8_lrelu_expand (LeakyReLU (None, 144, 216, 8)  0           block_8_conv_bn_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_8_dropout_expand (Dropout (None, 144, 216, 8)  0           block_8_lrelu_expand[0][0]       \n","__________________________________________________________________________________________________\n","block_9_trans_conv2d_expand (Co (None, 288, 432, 4)  132         block_8_dropout_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_9_concatenate_expand (Con (None, 288, 432, 8)  0           block_9_trans_conv2d_expand[0][0]\n","                                                                 block_1_lrelu_contract[0][0]     \n","__________________________________________________________________________________________________\n","block_9_conv2d_1_expand (Conv2D (None, 288, 432, 4)  292         block_9_concatenate_expand[0][0] \n","__________________________________________________________________________________________________\n","block_9_conv2d_2_expand (Conv2D (None, 288, 432, 4)  148         block_9_conv2d_1_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_9_conv_bn_expand (BatchNo (None, 288, 432, 4)  16          block_9_conv2d_2_expand[0][0]    \n","__________________________________________________________________________________________________\n","block_9_lrelu_expand (LeakyReLU (None, 288, 432, 4)  0           block_9_conv_bn_expand[0][0]     \n","__________________________________________________________________________________________________\n","block_9_dropout_expand (Dropout (None, 288, 432, 4)  0           block_9_lrelu_expand[0][0]       \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 288, 432, 3)  15          block_9_dropout_expand[0][0]     \n","==================================================================================================\n","Total params: 122,471\n","Trainable params: 122,103\n","Non-trainable params: 368\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"86ZWvGhsBMPw"},"source":["regularizer = tf.keras.regularizers.l2(.0001)\n","\n","for layer in U_net.layers:\n","    if layer.trainable == True:\n","        for attr in ['kernel_regularizer']:\n","            if hasattr(layer, attr):\n","                setattr(layer, attr, regularizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n834rLAPYx-a","executionInfo":{"status":"ok","timestamp":1602410353238,"user_tz":-330,"elapsed":314014,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"abc51dfb-127f-4594-b41c-5bf820c79718","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["U_net.fit(train_1,train_1, batch_size=32,\tvalidation_data=(test_1,test_1),\tepochs=50, verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","19/19 - 7s - loss: 0.1906 - val_loss: 0.1475\n","Epoch 2/50\n","19/19 - 5s - loss: 0.1711 - val_loss: 0.1424\n","Epoch 3/50\n","19/19 - 5s - loss: 0.1554 - val_loss: 0.1363\n","Epoch 4/50\n","19/19 - 5s - loss: 0.1441 - val_loss: 0.1307\n","Epoch 5/50\n","19/19 - 5s - loss: 0.1362 - val_loss: 0.1273\n","Epoch 6/50\n","19/19 - 5s - loss: 0.1306 - val_loss: 0.1250\n","Epoch 7/50\n","19/19 - 5s - loss: 0.1265 - val_loss: 0.1226\n","Epoch 8/50\n","19/19 - 5s - loss: 0.1232 - val_loss: 0.1199\n","Epoch 9/50\n","19/19 - 5s - loss: 0.1205 - val_loss: 0.1174\n","Epoch 10/50\n","19/19 - 5s - loss: 0.1181 - val_loss: 0.1156\n","Epoch 11/50\n","19/19 - 5s - loss: 0.1160 - val_loss: 0.1131\n","Epoch 12/50\n","19/19 - 5s - loss: 0.1142 - val_loss: 0.1106\n","Epoch 13/50\n","19/19 - 5s - loss: 0.1126 - val_loss: 0.1085\n","Epoch 14/50\n","19/19 - 5s - loss: 0.1111 - val_loss: 0.1064\n","Epoch 15/50\n","19/19 - 5s - loss: 0.1097 - val_loss: 0.1044\n","Epoch 16/50\n","19/19 - 5s - loss: 0.1084 - val_loss: 0.1029\n","Epoch 17/50\n","19/19 - 5s - loss: 0.1072 - val_loss: 0.1014\n","Epoch 18/50\n","19/19 - 5s - loss: 0.1061 - val_loss: 0.0999\n","Epoch 19/50\n","19/19 - 5s - loss: 0.1050 - val_loss: 0.0987\n","Epoch 20/50\n","19/19 - 5s - loss: 0.1040 - val_loss: 0.0977\n","Epoch 21/50\n","19/19 - 5s - loss: 0.1030 - val_loss: 0.0968\n","Epoch 22/50\n","19/19 - 5s - loss: 0.1020 - val_loss: 0.0959\n","Epoch 23/50\n","19/19 - 5s - loss: 0.1011 - val_loss: 0.0951\n","Epoch 24/50\n","19/19 - 5s - loss: 0.1002 - val_loss: 0.0943\n","Epoch 25/50\n","19/19 - 5s - loss: 0.0993 - val_loss: 0.0935\n","Epoch 26/50\n","19/19 - 5s - loss: 0.0985 - val_loss: 0.0928\n","Epoch 27/50\n","19/19 - 5s - loss: 0.0977 - val_loss: 0.0920\n","Epoch 28/50\n","19/19 - 5s - loss: 0.0969 - val_loss: 0.0913\n","Epoch 29/50\n","19/19 - 5s - loss: 0.0961 - val_loss: 0.0907\n","Epoch 30/50\n","19/19 - 5s - loss: 0.0953 - val_loss: 0.0900\n","Epoch 31/50\n","19/19 - 5s - loss: 0.0945 - val_loss: 0.0895\n","Epoch 32/50\n","19/19 - 5s - loss: 0.0938 - val_loss: 0.0889\n","Epoch 33/50\n","19/19 - 5s - loss: 0.0931 - val_loss: 0.0883\n","Epoch 34/50\n","19/19 - 5s - loss: 0.0923 - val_loss: 0.0877\n","Epoch 35/50\n","19/19 - 5s - loss: 0.0916 - val_loss: 0.0872\n","Epoch 36/50\n","19/19 - 5s - loss: 0.0909 - val_loss: 0.0865\n","Epoch 37/50\n","19/19 - 5s - loss: 0.0902 - val_loss: 0.0859\n","Epoch 38/50\n","19/19 - 5s - loss: 0.0895 - val_loss: 0.0855\n","Epoch 39/50\n","19/19 - 5s - loss: 0.0889 - val_loss: 0.0847\n","Epoch 40/50\n","19/19 - 5s - loss: 0.0882 - val_loss: 0.0841\n","Epoch 41/50\n","19/19 - 5s - loss: 0.0876 - val_loss: 0.0835\n","Epoch 42/50\n","19/19 - 5s - loss: 0.0869 - val_loss: 0.0829\n","Epoch 43/50\n","19/19 - 5s - loss: 0.0863 - val_loss: 0.0824\n","Epoch 44/50\n","19/19 - 5s - loss: 0.0857 - val_loss: 0.0818\n","Epoch 45/50\n","19/19 - 5s - loss: 0.0850 - val_loss: 0.0811\n","Epoch 46/50\n","19/19 - 5s - loss: 0.0844 - val_loss: 0.0806\n","Epoch 47/50\n","19/19 - 5s - loss: 0.0838 - val_loss: 0.0801\n","Epoch 48/50\n","19/19 - 5s - loss: 0.0832 - val_loss: 0.0794\n","Epoch 49/50\n","19/19 - 5s - loss: 0.0826 - val_loss: 0.0787\n","Epoch 50/50\n","19/19 - 5s - loss: 0.0820 - val_loss: 0.0783\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fa1a43c8f98>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ZSR9ZFTclvAJ"},"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten,Reshape,Cropping2D,Conv2DTranspose,concatenate,BatchNormalization,Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.initializers import orthogonal\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x72mvXe_Rt6_","executionInfo":{"status":"ok","timestamp":1602419255582,"user_tz":-60,"elapsed":7533,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"6536cb16-5e12-4958-f2c9-b4ca33c4229a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["batch_size = 10\n","epochs = 200\n","inChannel = 3\n","x, y = 288, 432\n","input_img = Input(shape = (x, y, inChannel))\n","num_classes = 5\n","\n","def encoder(input_img):\n","    #encoder\n","    #input = 28 x 28 x 1 (wide and thin)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    return conv4\n","\n","def decoder(conv4):    \n","    #decoder\n","    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n","    conv5 = BatchNormalization()(conv5)\n","    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n","    conv5 = BatchNormalization()(conv5)\n","    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n","    conv6 = BatchNormalization()(conv6)\n","    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n","    conv6 = BatchNormalization()(conv6)\n","    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n","    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n","    conv7 = BatchNormalization()(conv7)\n","    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n","    conv7 = BatchNormalization()(conv7)\n","    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n","    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n","    return decoded\n","\n","autoencoder = Model(input_img, decoder(encoder(input_img)))\n","autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n","autoencoder.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 288, 432, 3)]     0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 288, 432, 32)      896       \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 288, 432, 32)      128       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 288, 432, 32)      9248      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 288, 432, 32)      128       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 144, 216, 32)      0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 144, 216, 64)      18496     \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 144, 216, 64)      256       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 144, 216, 64)      36928     \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 144, 216, 64)      256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 72, 108, 64)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 72, 108, 128)      73856     \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 72, 108, 128)      147584    \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 72, 108, 256)      295168    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 72, 108, 256)      1024      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 72, 108, 256)      1024      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 72, 108, 128)      295040    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 72, 108, 128)      147584    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 72, 108, 64)       73792     \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 72, 108, 64)       256       \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 72, 108, 64)       36928     \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 72, 108, 64)       256       \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 144, 216, 64)      0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 144, 216, 32)      18464     \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 144, 216, 32)      128       \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 144, 216, 32)      9248      \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 144, 216, 32)      128       \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 288, 432, 32)      0         \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 288, 432, 3)       867       \n","=================================================================\n","Total params: 1,759,811\n","Trainable params: 1,756,995\n","Non-trainable params: 2,816\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aS8Rk0rYS-qV","executionInfo":{"status":"ok","timestamp":1602421476523,"user_tz":-60,"elapsed":2217686,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"91c9ad7a-5e34-48a1-9014-42d0b2959c0c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["regularizer = tf.keras.regularizers.l2(.0001)\n","batch_size=20\n","for layer in autoencoder.layers:\n","    if layer.trainable == True:\n","        for attr in ['kernel_regularizer']:\n","            if hasattr(layer, attr):\n","                setattr(layer, attr, regularizer)\n","autoencoder.fit(train_1,train_1, batch_size=batch_size,\tvalidation_data=(test_1,test_1),\tepochs=100, verbose=2, use_multiprocessing=True, workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1122s vs `on_train_batch_end` time: 0.2126s). Check your callbacks.\n","61/61 - 25s - loss: 0.0244 - val_loss: 0.0605\n","Epoch 2/100\n","61/61 - 21s - loss: 0.0096 - val_loss: 0.0743\n","Epoch 3/100\n","61/61 - 21s - loss: 0.0070 - val_loss: 0.1348\n","Epoch 4/100\n","61/61 - 21s - loss: 0.0053 - val_loss: 0.0279\n","Epoch 5/100\n","61/61 - 21s - loss: 0.0048 - val_loss: 0.0548\n","Epoch 6/100\n","61/61 - 22s - loss: 0.0045 - val_loss: 0.0280\n","Epoch 7/100\n","61/61 - 22s - loss: 0.0040 - val_loss: 0.0145\n","Epoch 8/100\n","61/61 - 22s - loss: 0.0040 - val_loss: 0.0206\n","Epoch 9/100\n","61/61 - 22s - loss: 0.0037 - val_loss: 0.0205\n","Epoch 10/100\n","61/61 - 22s - loss: 0.0036 - val_loss: 0.0057\n","Epoch 11/100\n","61/61 - 22s - loss: 0.0034 - val_loss: 0.0094\n","Epoch 12/100\n","61/61 - 22s - loss: 0.0033 - val_loss: 0.0058\n","Epoch 13/100\n","61/61 - 22s - loss: 0.0032 - val_loss: 0.0089\n","Epoch 14/100\n","61/61 - 22s - loss: 0.0029 - val_loss: 0.0077\n","Epoch 15/100\n","61/61 - 22s - loss: 0.0029 - val_loss: 0.0035\n","Epoch 16/100\n","61/61 - 22s - loss: 0.0029 - val_loss: 0.0031\n","Epoch 17/100\n","61/61 - 22s - loss: 0.0028 - val_loss: 0.0041\n","Epoch 18/100\n","61/61 - 22s - loss: 0.0026 - val_loss: 0.0045\n","Epoch 19/100\n","61/61 - 22s - loss: 0.0028 - val_loss: 0.0034\n","Epoch 20/100\n","61/61 - 22s - loss: 0.0025 - val_loss: 0.0036\n","Epoch 21/100\n","61/61 - 22s - loss: 0.0027 - val_loss: 0.0043\n","Epoch 22/100\n","61/61 - 22s - loss: 0.0026 - val_loss: 0.0037\n","Epoch 23/100\n","61/61 - 22s - loss: 0.0025 - val_loss: 0.0032\n","Epoch 24/100\n","61/61 - 22s - loss: 0.0025 - val_loss: 0.0050\n","Epoch 25/100\n","61/61 - 22s - loss: 0.0025 - val_loss: 0.1057\n","Epoch 26/100\n","61/61 - 22s - loss: 0.0025 - val_loss: 0.0052\n","Epoch 27/100\n","61/61 - 22s - loss: 0.0023 - val_loss: 0.0023\n","Epoch 28/100\n","61/61 - 22s - loss: 0.0024 - val_loss: 0.0034\n","Epoch 29/100\n","61/61 - 22s - loss: 0.0024 - val_loss: 0.0024\n","Epoch 30/100\n","61/61 - 22s - loss: 0.0023 - val_loss: 0.0051\n","Epoch 31/100\n","61/61 - 22s - loss: 0.0023 - val_loss: 0.0029\n","Epoch 32/100\n","61/61 - 22s - loss: 0.0023 - val_loss: 0.0025\n","Epoch 33/100\n","61/61 - 22s - loss: 0.0026 - val_loss: 0.0023\n","Epoch 34/100\n","61/61 - 22s - loss: 0.0022 - val_loss: 0.0024\n","Epoch 35/100\n","61/61 - 22s - loss: 0.0022 - val_loss: 0.0028\n","Epoch 36/100\n","61/61 - 22s - loss: 0.0021 - val_loss: 0.0022\n","Epoch 37/100\n","61/61 - 22s - loss: 0.0021 - val_loss: 0.0035\n","Epoch 38/100\n","61/61 - 22s - loss: 0.0020 - val_loss: 0.0030\n","Epoch 39/100\n","61/61 - 22s - loss: 0.0021 - val_loss: 0.0023\n","Epoch 40/100\n","61/61 - 22s - loss: 0.0020 - val_loss: 0.0026\n","Epoch 41/100\n","61/61 - 22s - loss: 0.0020 - val_loss: 0.0045\n","Epoch 42/100\n","61/61 - 22s - loss: 0.0019 - val_loss: 0.0022\n","Epoch 43/100\n","61/61 - 22s - loss: 0.0020 - val_loss: 0.0023\n","Epoch 44/100\n","61/61 - 22s - loss: 0.0019 - val_loss: 0.0020\n","Epoch 45/100\n","61/61 - 22s - loss: 0.0019 - val_loss: 0.0026\n","Epoch 46/100\n","61/61 - 22s - loss: 0.0021 - val_loss: 0.0022\n","Epoch 47/100\n","61/61 - 22s - loss: 0.0018 - val_loss: 0.0036\n","Epoch 48/100\n","61/61 - 22s - loss: 0.0019 - val_loss: 0.0027\n","Epoch 49/100\n","61/61 - 22s - loss: 0.0018 - val_loss: 0.0032\n","Epoch 50/100\n","61/61 - 22s - loss: 0.0018 - val_loss: 0.0020\n","Epoch 51/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0022\n","Epoch 52/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0018\n","Epoch 53/100\n","61/61 - 22s - loss: 0.0018 - val_loss: 0.0018\n","Epoch 54/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0020\n","Epoch 55/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0019\n","Epoch 56/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0023\n","Epoch 57/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0019\n","Epoch 58/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0018\n","Epoch 59/100\n","61/61 - 22s - loss: 0.0017 - val_loss: 0.0015\n","Epoch 60/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0018\n","Epoch 61/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0016\n","Epoch 62/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0016\n","Epoch 63/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0019\n","Epoch 64/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0016\n","Epoch 65/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0032\n","Epoch 66/100\n","61/61 - 22s - loss: 0.0016 - val_loss: 0.0020\n","Epoch 67/100\n","61/61 - 22s - loss: 0.0015 - val_loss: 0.0015\n","Epoch 68/100\n","61/61 - 22s - loss: 0.0015 - val_loss: 0.0017\n","Epoch 69/100\n","61/61 - 22s - loss: 0.0015 - val_loss: 0.0016\n","Epoch 70/100\n","61/61 - 22s - loss: 0.0015 - val_loss: 0.0015\n","Epoch 71/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0029\n","Epoch 72/100\n","61/61 - 22s - loss: 0.0015 - val_loss: 0.0017\n","Epoch 73/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0018\n","Epoch 74/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0046\n","Epoch 75/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0014\n","Epoch 76/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0016\n","Epoch 77/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0018\n","Epoch 78/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0018\n","Epoch 79/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0019\n","Epoch 80/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0016\n","Epoch 81/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0014\n","Epoch 82/100\n","61/61 - 22s - loss: 0.0014 - val_loss: 0.0015\n","Epoch 83/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0015\n","Epoch 84/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0014\n","Epoch 85/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0020\n","Epoch 86/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0013\n","Epoch 87/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0016\n","Epoch 88/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0013\n","Epoch 89/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0013\n","Epoch 90/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0013\n","Epoch 91/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0018\n","Epoch 92/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0014\n","Epoch 93/100\n","61/61 - 22s - loss: 0.0013 - val_loss: 0.0017\n","Epoch 94/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0012\n","Epoch 95/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0014\n","Epoch 96/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0013\n","Epoch 97/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0012\n","Epoch 98/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0015\n","Epoch 99/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0015\n","Epoch 100/100\n","61/61 - 22s - loss: 0.0012 - val_loss: 0.0012\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb8bc08f668>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ETbJ_-9lV2c9"},"source":["autoencoder.save_weights('autoencoder.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvOXvA5qaG-R","executionInfo":{"status":"ok","timestamp":1602421662870,"user_tz":-60,"elapsed":1441,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"11dde4b4-24a4-473d-f5d6-7278da809e0c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from tensorflow.keras.layers import GlobalAveragePooling2D, AveragePooling2D\n","batch_size = 10\n","epochs = 200\n","inChannel = 3\n","x, y = 288, 432\n","input_img = Input(shape = (x, y, inChannel))\n","num_classes = 5\n","\n","def encoder(input_img):\n","    #encoder\n","    #input = 28 x 28 x 1 (wide and thin)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n","    conv3 = BatchNormalization()(conv3)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n","    conv4 = BatchNormalization()(conv4)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    avgpool = GlobalAveragePooling2D()(conv4)\n","    return avgpool\n","\n","def fc(enco):\n","    flat = Flatten()(enco)\n","    den = Dense(128, activation='relu')(flat)\n","    den = Dense(64, activation='relu')(den)\n","    out = Dense(num_classes, activation='softmax')(den)\n","    return out\n","\n","encode = encoder(input_img)\n","full_model = Model(input_img,fc(encode)) \n","for l1,l2 in zip(full_model.layers[:19],autoencoder.layers[0:19]):\n","    l1.set_weights(l2.get_weights())\n","\n","for layer in full_model.layers[0:19]:\n","    layer.trainable = False \n","\n","full_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.SGD(),metrics=['accuracy'])      \n","full_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, 288, 432, 3)]     0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 288, 432, 32)      896       \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 288, 432, 32)      128       \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 288, 432, 32)      9248      \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 288, 432, 32)      128       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 144, 216, 32)      0         \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 144, 216, 64)      18496     \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 144, 216, 64)      256       \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 144, 216, 64)      36928     \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 144, 216, 64)      256       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 72, 108, 64)       0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 72, 108, 128)      73856     \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 72, 108, 128)      147584    \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 72, 108, 128)      512       \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 72, 108, 256)      295168    \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 72, 108, 256)      1024      \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 72, 108, 256)      590080    \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 72, 108, 256)      1024      \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 256)               0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 128)               32896     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 1,217,573\n","Trainable params: 41,477\n","Non-trainable params: 1,176,096\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9pQa4NVRchvY","executionInfo":{"status":"ok","timestamp":1602422728429,"user_tz":-60,"elapsed":253397,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"7fbe238a-461a-4aeb-d64f-689d6c0908b1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["full_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\n","full_model.fit(train_1, train_lab_1, batch_size=20,epochs=50,verbose=2,validation_data=(test_1, test_lab_1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","31/31 - 5s - loss: 0.0912 - accuracy: 0.9868 - val_loss: 0.9469 - val_accuracy: 0.7351\n","Epoch 2/50\n","31/31 - 5s - loss: 0.0655 - accuracy: 0.9901 - val_loss: 0.9393 - val_accuracy: 0.7417\n","Epoch 3/50\n","31/31 - 5s - loss: 0.0717 - accuracy: 0.9901 - val_loss: 0.9171 - val_accuracy: 0.7417\n","Epoch 4/50\n","31/31 - 5s - loss: 0.0864 - accuracy: 0.9802 - val_loss: 1.0491 - val_accuracy: 0.7086\n","Epoch 5/50\n","31/31 - 5s - loss: 0.0995 - accuracy: 0.9736 - val_loss: 0.9931 - val_accuracy: 0.7219\n","Epoch 6/50\n","31/31 - 5s - loss: 0.0684 - accuracy: 0.9884 - val_loss: 0.9961 - val_accuracy: 0.7351\n","Epoch 7/50\n","31/31 - 5s - loss: 0.0600 - accuracy: 0.9950 - val_loss: 0.9903 - val_accuracy: 0.7285\n","Epoch 8/50\n","31/31 - 5s - loss: 0.0656 - accuracy: 0.9950 - val_loss: 1.0088 - val_accuracy: 0.7351\n","Epoch 9/50\n","31/31 - 5s - loss: 0.1227 - accuracy: 0.9670 - val_loss: 1.1365 - val_accuracy: 0.7152\n","Epoch 10/50\n","31/31 - 5s - loss: 0.1698 - accuracy: 0.9488 - val_loss: 1.2487 - val_accuracy: 0.6954\n","Epoch 11/50\n","31/31 - 5s - loss: 0.2378 - accuracy: 0.9455 - val_loss: 1.0918 - val_accuracy: 0.7285\n","Epoch 12/50\n","31/31 - 5s - loss: 0.0920 - accuracy: 0.9785 - val_loss: 1.0762 - val_accuracy: 0.7086\n","Epoch 13/50\n","31/31 - 5s - loss: 0.0624 - accuracy: 0.9934 - val_loss: 1.0136 - val_accuracy: 0.7285\n","Epoch 14/50\n","31/31 - 5s - loss: 0.0505 - accuracy: 0.9950 - val_loss: 0.9966 - val_accuracy: 0.7351\n","Epoch 15/50\n","31/31 - 5s - loss: 0.0448 - accuracy: 0.9967 - val_loss: 0.9877 - val_accuracy: 0.7351\n","Epoch 16/50\n","31/31 - 5s - loss: 0.0429 - accuracy: 0.9967 - val_loss: 1.0011 - val_accuracy: 0.7351\n","Epoch 17/50\n","31/31 - 5s - loss: 0.0425 - accuracy: 0.9967 - val_loss: 0.9820 - val_accuracy: 0.7417\n","Epoch 18/50\n","31/31 - 5s - loss: 0.0423 - accuracy: 0.9983 - val_loss: 1.0089 - val_accuracy: 0.7285\n","Epoch 19/50\n","31/31 - 5s - loss: 0.0442 - accuracy: 0.9950 - val_loss: 1.0414 - val_accuracy: 0.7152\n","Epoch 20/50\n","31/31 - 5s - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.7417\n","Epoch 21/50\n","31/31 - 5s - loss: 0.0423 - accuracy: 0.9983 - val_loss: 0.9592 - val_accuracy: 0.7483\n","Epoch 22/50\n","31/31 - 5s - loss: 0.0406 - accuracy: 0.9983 - val_loss: 1.0480 - val_accuracy: 0.7417\n","Epoch 23/50\n","31/31 - 5s - loss: 0.0368 - accuracy: 0.9983 - val_loss: 1.0143 - val_accuracy: 0.7351\n","Epoch 24/50\n","31/31 - 5s - loss: 0.0356 - accuracy: 0.9983 - val_loss: 1.0298 - val_accuracy: 0.7351\n","Epoch 25/50\n","31/31 - 5s - loss: 0.0383 - accuracy: 0.9967 - val_loss: 1.0216 - val_accuracy: 0.7152\n","Epoch 26/50\n","31/31 - 5s - loss: 0.0475 - accuracy: 0.9934 - val_loss: 1.0133 - val_accuracy: 0.7483\n","Epoch 27/50\n","31/31 - 5s - loss: 0.0407 - accuracy: 1.0000 - val_loss: 1.0203 - val_accuracy: 0.7219\n","Epoch 28/50\n","31/31 - 5s - loss: 0.0346 - accuracy: 0.9967 - val_loss: 1.0540 - val_accuracy: 0.7483\n","Epoch 29/50\n","31/31 - 5s - loss: 0.0393 - accuracy: 0.9983 - val_loss: 1.0789 - val_accuracy: 0.7219\n","Epoch 30/50\n","31/31 - 5s - loss: 0.0328 - accuracy: 0.9983 - val_loss: 1.0231 - val_accuracy: 0.7351\n","Epoch 31/50\n","31/31 - 5s - loss: 0.0375 - accuracy: 0.9934 - val_loss: 1.1711 - val_accuracy: 0.7020\n","Epoch 32/50\n","31/31 - 5s - loss: 0.0603 - accuracy: 0.9851 - val_loss: 1.0225 - val_accuracy: 0.7550\n","Epoch 33/50\n","31/31 - 5s - loss: 0.0496 - accuracy: 0.9884 - val_loss: 1.0448 - val_accuracy: 0.7417\n","Epoch 34/50\n","31/31 - 5s - loss: 0.0791 - accuracy: 0.9851 - val_loss: 1.0929 - val_accuracy: 0.7616\n","Epoch 35/50\n","31/31 - 5s - loss: 0.0892 - accuracy: 0.9769 - val_loss: 1.2751 - val_accuracy: 0.7020\n","Epoch 36/50\n","31/31 - 5s - loss: 0.0731 - accuracy: 0.9802 - val_loss: 1.1433 - val_accuracy: 0.7550\n","Epoch 37/50\n","31/31 - 5s - loss: 0.1133 - accuracy: 0.9703 - val_loss: 1.1749 - val_accuracy: 0.7285\n","Epoch 38/50\n","31/31 - 5s - loss: 0.0659 - accuracy: 0.9835 - val_loss: 1.1396 - val_accuracy: 0.7417\n","Epoch 39/50\n","31/31 - 5s - loss: 0.0507 - accuracy: 0.9901 - val_loss: 1.1298 - val_accuracy: 0.7351\n","Epoch 40/50\n","31/31 - 5s - loss: 0.0478 - accuracy: 0.9950 - val_loss: 1.0362 - val_accuracy: 0.7351\n","Epoch 41/50\n","31/31 - 5s - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.0758 - val_accuracy: 0.7550\n","Epoch 42/50\n","31/31 - 5s - loss: 0.0313 - accuracy: 0.9983 - val_loss: 1.1096 - val_accuracy: 0.7550\n","Epoch 43/50\n","31/31 - 5s - loss: 0.0339 - accuracy: 0.9967 - val_loss: 1.0949 - val_accuracy: 0.7550\n","Epoch 44/50\n","31/31 - 5s - loss: 0.0324 - accuracy: 0.9950 - val_loss: 1.1089 - val_accuracy: 0.7417\n","Epoch 45/50\n","31/31 - 5s - loss: 0.0278 - accuracy: 0.9983 - val_loss: 1.0811 - val_accuracy: 0.7550\n","Epoch 46/50\n","31/31 - 5s - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.7616\n","Epoch 47/50\n","31/31 - 5s - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.7483\n","Epoch 48/50\n","31/31 - 5s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.7285\n","Epoch 49/50\n","31/31 - 5s - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.7483\n","Epoch 50/50\n","31/31 - 5s - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.0672 - val_accuracy: 0.7417\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb8a6ce0588>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"JunktXP53LUl"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jTZMwDj4fj3W"},"source":["bottleneck_model = Model(inputs = full_model.input, outputs=full_model.get_layer('flatten_1').output)\n","def get_every_n(a, n=1):\n","  for i in range(a.shape[0] // n):\n","    yield a[n*i:n*(i+1)]\n","bottleneck=np.zeros((606,256))\n","bottleneck_test=np.zeros((151,256))\n","for j,sa in enumerate(get_every_n(train_1)):\n","   bottleneck[j]=bottleneck_model.predict(sa)\n","for j,sa in enumerate(get_every_n(test_1)):\n","   bottleneck_test[j]=bottleneck_model.predict(sa)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdIYCUMb7Zai","executionInfo":{"status":"ok","timestamp":1602424317671,"user_tz":-60,"elapsed":2698,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"aa1d84f9-9ce9-4e19-ed5d-df27a6371ae4","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print(bottleneck.shape)\n","print(bottleneck_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(606, 256)\n","(151, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WADFaObB4Brk","executionInfo":{"status":"ok","timestamp":1602410355056,"user_tz":-330,"elapsed":315809,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"d941f411-9a5a-40e5-85fe-b9b1b8fc2e87","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["bottleneck_model = Model(inputs = U_net.input, outputs=U_net.get_layer('flatten_bottleneck').output)\n","\n","bottleneck = bottleneck_model.predict(train_1)\n","\n","print(bottleneck.shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(606, 31104)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5dBQDxI9NwFS","executionInfo":{"status":"ok","timestamp":1602412370949,"user_tz":-330,"elapsed":1612,"user":{"displayName":"SAHIL JINDAL","photoUrl":"","userId":"17061076833624679412"}},"outputId":"13f008cc-3608-4618-9559-2a543429fcfd","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["bottleneck_test = bottleneck_model.predict(test_1)\n","print(bottleneck_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(151, 31104)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yNkFs_ICMeU_","executionInfo":{"status":"ok","timestamp":1602424591214,"user_tz":-60,"elapsed":1426,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"8d005d47-9cf2-4261-b46a-b44d14f5741e","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_lab_1 = np.load(r'/content/drive/My Drive/stratified k fold data/train_lab_5.npy')\n","test_lab_1 = np.load(r'/content/drive/My Drive/stratified k fold data/test_lab_5.npy')\n","train_lab_1 = train_lab_1.argmax(1)\n","test_lab_1  =test_lab_1.argmax(1)\n","\n","print(test_lab_1.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(151,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NLDyJ0VEO1aD"},"source":["train_lab_1 = train_lab_1.reshape(len(train_lab_1),1)\n","test_lab_1 = test_lab_1.reshape(len(test_lab_1),1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KlIcCanKPC9z","executionInfo":{"status":"ok","timestamp":1602424601734,"user_tz":-60,"elapsed":1884,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"f4e734ea-6679-4902-f92d-4cb1ffe1b1fd","colab":{"base_uri":"https://localhost:8080/","height":211}},"source":["print(train_lab_1.shape)\n","print(train_lab_1[0:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(606, 1)\n","[[3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]\n"," [3]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uFNhd3JLfHP","executionInfo":{"status":"ok","timestamp":1602424637839,"user_tz":-60,"elapsed":2415,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"c166f833-1cc6-48c1-993b-aa1109719d3a","colab":{"base_uri":"https://localhost:8080/","height":213}},"source":["from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","clf = RandomForestClassifier()\n","\n","clf.fit(bottleneck,train_lab_1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  after removing the cwd from sys.path.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"YeTmiRl-Nlrn","executionInfo":{"status":"ok","timestamp":1602424642702,"user_tz":-60,"elapsed":1391,"user":{"displayName":"Vinayak Abrol","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAP8HFz92R0aT_n9wI9nSe0ll-ApnqWdPETQnTlw=s64","userId":"14475243480361490768"}},"outputId":"12c13eea-2f32-40b8-990d-ed475494f90f","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["predicted_test = clf.predict(bottleneck_test)\n","print(predicted_test.shape)\n","#predicted_test = predicted_test.reshape((len(predicted_test),1))\n","#print(predicted_test.shape)\n","\n","\n","import sklearn\n","acc_test = sklearn.metrics.accuracy_score(predicted_test,test_lab_1)\n","print(acc_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(151,)\n","0.695364238410596\n"],"name":"stdout"}]}]}